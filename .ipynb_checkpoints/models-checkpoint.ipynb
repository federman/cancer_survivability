{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#race = \"hispanic\"\n",
    "#race = \"white\"\n",
    "#race = \"mixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('../Data/' + race + '/X.npy')\n",
    "#Y2 = np.load('../Data/' + race + '/Y2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hispanic = np.load('../Data/hispanic/X.npy')\n",
    "Y_hispanic = np.load('../Data/hispanic/Y2.npy')\n",
    "X_white = np.load('../Data/white/X.npy')\n",
    "Y_white = np.load('../Data/white/Y2.npy')\n",
    "#X_mixed = np.load('../Data/mixed/X.npy')\n",
    "#Y_mixed = np.load('../Data/mixed/Y2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37575, 301)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hispanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 93, 0, 4, 30], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hispanic[0,281:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_hispanic=37575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(X, Y):\n",
    "    # shuffle\n",
    "    np.random.seed(97)\n",
    "    idx = np.random.permutation(len(X))\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "    \n",
    "    #X = X[:size_hispanic]\n",
    "    #Y = Y[:size_hispanic]\n",
    "\n",
    "    # split into training and test sets\n",
    "    TEST_SET_SIZE = int(0.1*len(Y))\n",
    "    X_train, X_test = X[:-TEST_SET_SIZE], X[-TEST_SET_SIZE:]\n",
    "    Y_train, Y_test = Y[:-TEST_SET_SIZE].astype(int), Y[-TEST_SET_SIZE:].astype(int)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_h, X_test_h, Y_train_h, Y_test_h = split_train_test(X_hispanic, Y_hispanic)\n",
    "X_train_w, X_test_w, Y_train_w, Y_test_w = split_train_test(X_white, Y_white)\n",
    "#X_train_m, X_test_m, Y_train_m, Y_test_m = split_train_test(X_mixed, Y_mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "Fit scaler based on training data, then transform both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# feature scaling: scale features based on training data only\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def feature_scale(X_train, X_test):\n",
    "    \n",
    "    mm_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    X_train[:,-4:] = mm_scaler.fit_transform(X_train[:,-4:])\n",
    "    X_test[:,-4:] = mm_scaler.transform(X_test[:,-4:])\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train[:,:-4] = std_scaler.fit_transform(X_train[:,:-4])\n",
    "    X_test[:,:-4] = std_scaler.transform(X_test[:,:-4])\n",
    "    return X_train, X_test\n",
    "\n",
    "X_train_h, X_test_h = feature_scale(X_train_h, X_test_h)\n",
    "X_train_w, X_test_w = feature_scale(X_train_w, X_test_w)\n",
    "#X_train_m, X_test_m = feature_scale(X_train_m, X_test_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def results(classifier, X_test, Y_test):\n",
    "    Y_pred_test = classifier.predict(X_test)\n",
    "    print(\"Test accuracy score: \" + str(accuracy_score(Y_test.astype(int), Y_pred_test)))\n",
    "    print(\"ROC: \" + str(roc_auc_score(Y_test, classifier.predict_proba(X_test)[:,1])))\n",
    "    #print(\"ROC: \" + str(roc_auc_score(Y_test, Y_pred_test)))\n",
    "    matrix = confusion_matrix(Y_test.astype(int), Y_pred_test)\n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    ppv = tp/(tp+fp)\n",
    "    npv = tn/(tn+fn)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    g_mean = np.sqrt(sensitivity*specificity)\n",
    "    print(\"PPV: \" + str(ppv))\n",
    "    print(\"NPV: \" + str(npv))\n",
    "    print(\"Sensitivity: \" + str(sensitivity))\n",
    "    print(\"Specificity: \" + str(specificity))\n",
    "    print(\"G-Mean: \" + str(g_mean))\n",
    "    print(\"Confusion matrix:\\n\" + str(matrix))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# min_sample_split: 300,400\n",
    "# min_samples_leaf: 200\n",
    "# max_depth: 130\n",
    "# min_weight_fraction_leaf: .01\n",
    "param_grid = [{'max_depth':[40,50,60], 'min_samples_leaf':[250,260,270,280,290]}]\n",
    "tree_clf_reg = DecisionTreeClassifier()\n",
    "dt_grid_search = GridSearchCV(tree_clf_reg, param_grid, cv=3, scoring=make_scorer(roc_auc_score), verbose=3)\n",
    "dt_grid_search.fit(X_train_h, Y_train_h.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = dt_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(dt_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(dt_grid_search, X_test_h, Y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_h = DecisionTreeClassifier(max_depth=130, min_samples_leaf=200)\n",
    "tree_clf_h.fit(X_train_h, Y_train_h)\n",
    "\n",
    "tree_clf_w = DecisionTreeClassifier(max_depth=130, min_samples_leaf=200)\n",
    "tree_clf_w.fit(X_train_w, Y_train_w)\n",
    "\n",
    "tree_clf_m = DecisionTreeClassifier(max_depth=130, min_samples_leaf=200)\n",
    "tree_clf_m.fit(X_train_m, Y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(tree_clf_h, X_test_h, Y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(tree_clf_w, X_test_w, Y_test_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(tree_clf_m, X_test_m, Y_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h = dict(enumerate(tree_clf_h.feature_importances_))\n",
    "sorted(d_h, key=d_h.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_w = dict(enumerate(tree_clf_w.feature_importances_))\n",
    "sorted(d_w, key=d_w.get, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(knn_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ................. C=0.01, score=0.6992168367903329, total=   1.5s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=0.01, score=0.700153633445304, total=   1.5s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=0.01, score=0.69466771042928, total=   1.5s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=0.1, score=0.7052212354780437, total=   2.8s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=0.1, score=0.6996581478694397, total=   2.7s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] .................. C=0.1, score=0.6951793853867201, total=   2.8s\n",
      "[CV] C=0.75 ..........................................................\n",
      "[CV] ................. C=0.75, score=0.7059609083263989, total=   4.2s\n",
      "[CV] C=0.75 ..........................................................\n",
      "[CV] ................. C=0.75, score=0.7014997792313875, total=   4.3s\n",
      "[CV] C=0.75 ..........................................................\n",
      "[CV] ................. C=0.75, score=0.6966285864256561, total=   4.7s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................... C=1, score=0.7055044957294112, total=   4.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................... C=1, score=0.7020662997341228, total=   4.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................... C=1, score=0.6961719654210898, total=   4.8s\n",
      "[CV] C=1.5 ...........................................................\n",
      "[CV] ................... C=1.5, score=0.706134060672019, total=   4.7s\n",
      "[CV] C=1.5 ...........................................................\n",
      "[CV] .................. C=1.5, score=0.7019561918283752, total=   4.3s\n",
      "[CV] C=1.5 ...........................................................\n",
      "[CV] ................... C=1.5, score=0.696400275923373, total=   5.6s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .................... C=2, score=0.7062441685777667, total=   4.8s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .................... C=2, score=0.7024756488652353, total=   4.5s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .................... C=2, score=0.6962270193739637, total=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.01, 0.1, 0.75, 1, 1.5, 2]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(roc_auc_score), verbose=5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = [{'C':[.01, .1, .75, 1, 1.5, 2]}]\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3, \n",
    "                              scoring=make_scorer(roc_auc_score), verbose=5\n",
    "                             )\n",
    "lr_grid_search.fit(X_train_w, Y_train_w.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6980128258006144 {'C': 0.01}\n",
      "0.7000197327031548 {'C': 0.1}\n",
      "0.7013632313273677 {'C': 0.75}\n",
      "0.7012477370479314 {'C': 1}\n",
      "0.7014969935136673 {'C': 1.5}\n",
      "0.7016491059322929 {'C': 2}\n",
      "Best: {'C': 2}\n"
     ]
    }
   ],
   "source": [
    "cvres = lr_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(lr_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(lr_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8540320824562677\n",
      "ROC: 0.8707343684588752\n",
      "PPV: 0.884913611462284\n",
      "NPV: 0.6623953974895398\n",
      "Sensitivity: 0.9420816509645581\n",
      "Specificity: 0.481193009118541\n",
      "G-Mean: 0.6732927331131673\n",
      "Confusion matrix:\n",
      "[[ 2533  2731]\n",
      " [ 1291 20999]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(X_train_w, Y_train_w.astype(int))\n",
    "results(lr, X_test=X_test_w, Y_test=Y_test_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(363, 0.610851386708917),\n",
       " (71, 0.27051883424535456),\n",
       " (340, 0.20457990381025412),\n",
       " (177, 0.1572662770423993),\n",
       " (331, 0.15068680679402444),\n",
       " (251, 0.15012767329282642),\n",
       " (164, 0.13658806171747137),\n",
       " (182, 0.11876830937377733),\n",
       " (247, 0.10605701627513948),\n",
       " (202, 0.09552288315006163),\n",
       " (339, 0.0877107547846889),\n",
       " (233, 0.08184656030738441),\n",
       " (243, 0.08107293476543993),\n",
       " (1, 0.07695169524822658),\n",
       " (173, 0.06689424550126884),\n",
       " (52, 0.06548688895429705),\n",
       " (156, 0.06396656708815265),\n",
       " (313, 0.06352297239145206),\n",
       " (345, 0.06304098486493086),\n",
       " (316, 0.059980020414922224),\n",
       " (286, 0.057546888039859266),\n",
       " (9, 0.05598542942558552),\n",
       " (359, 0.0552996606248446),\n",
       " (172, 0.05494482403524912),\n",
       " (287, 0.054361535983506945),\n",
       " (43, 0.053512307967868246),\n",
       " (89, 0.052793537855950805),\n",
       " (157, 0.05275843062555647),\n",
       " (48, 0.051528615319774915),\n",
       " (139, 0.04944210062039059),\n",
       " (246, 0.049360743347171644),\n",
       " (288, 0.04934570600135513),\n",
       " (299, 0.049032428859048655),\n",
       " (88, 0.048443431185606116),\n",
       " (321, 0.047773571266608625),\n",
       " (280, 0.045651745442101564),\n",
       " (72, 0.045384312742301335),\n",
       " (103, 0.04207046080598516),\n",
       " (166, 0.04180954951060942),\n",
       " (174, 0.041641636305212525),\n",
       " (42, 0.041227720433898565),\n",
       " (65, 0.03908250134973316),\n",
       " (309, 0.03897120888228993),\n",
       " (245, 0.03803546847078757),\n",
       " (120, 0.03744309032972573),\n",
       " (149, 0.035517572353362774),\n",
       " (126, 0.03517023771591822),\n",
       " (304, 0.034361425161566025),\n",
       " (170, 0.03409061974814009),\n",
       " (87, 0.0340432165596742),\n",
       " (59, 0.033967641705026266),\n",
       " (171, 0.03386821629578099),\n",
       " (141, 0.03375565429347617),\n",
       " (152, 0.03147262105857229),\n",
       " (17, 0.03091775659760025),\n",
       " (341, 0.030853407248219635),\n",
       " (216, 0.030200476116445885),\n",
       " (206, 0.029863087880858886),\n",
       " (107, 0.028648311166127673),\n",
       " (154, 0.028584913489407865),\n",
       " (118, 0.028372048713414026),\n",
       " (276, 0.02788975502405101),\n",
       " (180, 0.027724027542416266),\n",
       " (130, 0.027376952184904227),\n",
       " (117, 0.02728357864116156),\n",
       " (49, 0.02699294396528959),\n",
       " (116, 0.026515292635352912),\n",
       " (25, 0.026431647924430333),\n",
       " (242, 0.02640673727770869),\n",
       " (76, 0.026253345485701313),\n",
       " (20, 0.025276797389559964),\n",
       " (258, 0.025101380981613658),\n",
       " (6, 0.02485829214193467),\n",
       " (84, 0.02475735156196282),\n",
       " (194, 0.024590645651218906),\n",
       " (125, 0.024520436540782047),\n",
       " (95, 0.024438358187143402),\n",
       " (151, 0.02439568965945674),\n",
       " (186, 0.024336878411167488),\n",
       " (127, 0.024254694540497872),\n",
       " (101, 0.023850358032569047),\n",
       " (15, 0.02381179898200475),\n",
       " (187, 0.023780375598761373),\n",
       " (7, 0.023044157110404924),\n",
       " (129, 0.0228114422689045),\n",
       " (250, 0.022666984032235393),\n",
       " (47, 0.022292611962909367),\n",
       " (312, 0.021741175029875277),\n",
       " (189, 0.02160251288566779),\n",
       " (135, 0.021281846252925896),\n",
       " (337, 0.020305664328633344),\n",
       " (64, 0.019830522858189824),\n",
       " (175, 0.0194457298065189),\n",
       " (252, 0.019384183424756913),\n",
       " (45, 0.019316068633674306),\n",
       " (51, 0.019099137541904933),\n",
       " (54, 0.01832275574047719),\n",
       " (131, 0.018211636710950555),\n",
       " (58, 0.018199027613008466),\n",
       " (181, 0.01815480824668208),\n",
       " (257, 0.018071236954672373),\n",
       " (207, 0.017956402017445864),\n",
       " (41, 0.017911880810409356),\n",
       " (62, 0.01779131420197377),\n",
       " (108, 0.017764799588555612),\n",
       " (34, 0.017704815891525557),\n",
       " (30, 0.017113256093600725),\n",
       " (55, 0.0169983345027534),\n",
       " (188, 0.016641033516468225),\n",
       " (153, 0.016408569425115562),\n",
       " (94, 0.016362149305911365),\n",
       " (138, 0.016046065843061324),\n",
       " (86, 0.015973805599230846),\n",
       " (150, 0.015533208644608873),\n",
       " (176, 0.0154129852609637),\n",
       " (301, 0.015162747698521448),\n",
       " (115, 0.01507055532591646),\n",
       " (209, 0.015001575702745247),\n",
       " (113, 0.014922338347032873),\n",
       " (23, 0.014910446794429603),\n",
       " (137, 0.014705607582594324),\n",
       " (128, 0.014535658236550997),\n",
       " (231, 0.014458465236047695),\n",
       " (134, 0.0142505615489623),\n",
       " (145, 0.01424201982421034),\n",
       " (112, 0.014184169533618594),\n",
       " (314, 0.01393261239024194),\n",
       " (24, 0.013302265413430967),\n",
       " (294, 0.013271994241377188),\n",
       " (44, 0.012745072042913348),\n",
       " (311, 0.012520756361908808),\n",
       " (274, 0.012291838703319808),\n",
       " (18, 0.011959618567067013),\n",
       " (282, 0.011737495428296456),\n",
       " (278, 0.011051096139534445),\n",
       " (305, 0.010916222165989928),\n",
       " (200, 0.010892945150525102),\n",
       " (254, 0.010858905052470696),\n",
       " (256, 0.010846080929827721),\n",
       " (90, 0.010812657008217652),\n",
       " (178, 0.00982721006035289),\n",
       " (183, 0.009785647215808277),\n",
       " (77, 0.009486638664336022),\n",
       " (93, 0.009405948784802583),\n",
       " (292, 0.009219672276819649),\n",
       " (208, 0.009003688629991678),\n",
       " (73, 0.00882277845679015),\n",
       " (83, 0.008651205503523156),\n",
       " (295, 0.008495954880611849),\n",
       " (160, 0.008327612609351054),\n",
       " (270, 0.008269111955917702),\n",
       " (353, 0.00802487734722759),\n",
       " (144, 0.00801571881363565),\n",
       " (184, 0.0077419755191613085),\n",
       " (201, 0.007478257556473516),\n",
       " (75, 0.007166128450234652),\n",
       " (204, 0.007060266979479727),\n",
       " (132, 0.006866044996900724),\n",
       " (53, 0.0063320556133979146),\n",
       " (162, 0.00582262064550504),\n",
       " (290, 0.005443980269326951),\n",
       " (70, 0.005191236093635554),\n",
       " (327, 0.005047957288682446),\n",
       " (19, 0.004915926456401966),\n",
       " (79, 0.004791929621078822),\n",
       " (143, 0.00438319382946919),\n",
       " (226, 0.0041845986257735834),\n",
       " (264, 0.004028747623829654),\n",
       " (253, 0.0032337991986553447),\n",
       " (261, 0.003090914103233643),\n",
       " (354, 0.003071127443943149),\n",
       " (347, 0.003070911723544533),\n",
       " (306, 0.0029924534176102835),\n",
       " (46, 0.0029294467663248816),\n",
       " (22, 0.002903141607187843),\n",
       " (33, 0.002469277275370153),\n",
       " (82, 0.0024470155368748778),\n",
       " (69, 0.0023597256896508156),\n",
       " (346, 0.0019775371166460927),\n",
       " (167, 0.0019057127151239181),\n",
       " (296, 0.001838160475380881),\n",
       " (123, 0.0018215903264002093),\n",
       " (14, 0.0017099499474683047),\n",
       " (142, 0.0015632645841054565),\n",
       " (148, 0.00147133650317219),\n",
       " (350, 0.0011610379652413996),\n",
       " (344, 0.0010895257079170952),\n",
       " (272, 0.0009705384037259308),\n",
       " (284, 0.0009299909297826605),\n",
       " (28, 0.0008617315134865791),\n",
       " (241, 0.0005459028056759717),\n",
       " (263, 0.0005115021522255315),\n",
       " (349, 0.00033491610348067953),\n",
       " (163, 0.00013160630356887535),\n",
       " (324, 5.794643027607914e-05),\n",
       " (27, 0.0),\n",
       " (100, 0.0),\n",
       " (136, 0.0),\n",
       " (147, 0.0),\n",
       " (322, -0.00034177930272301447),\n",
       " (308, -0.00041859592285239066),\n",
       " (240, -0.00043572718432909096),\n",
       " (193, -0.0007059953643078415),\n",
       " (124, -0.0007396773790958447),\n",
       " (179, -0.0008959671026545316),\n",
       " (91, -0.0010878894908987686),\n",
       " (196, -0.001291105742890403),\n",
       " (205, -0.0014945889573224833),\n",
       " (259, -0.0017241314840800695),\n",
       " (119, -0.0018392795610174064),\n",
       " (326, -0.002023680155278231),\n",
       " (165, -0.002074871151554186),\n",
       " (111, -0.0020871100221367795),\n",
       " (255, -0.0023223231628177942),\n",
       " (121, -0.002374685524089151),\n",
       " (293, -0.0025889751699170985),\n",
       " (238, -0.002662038098926295),\n",
       " (224, -0.0027534704610450594),\n",
       " (38, -0.002950867727070129),\n",
       " (221, -0.0030680275823977716),\n",
       " (133, -0.0030898497936105492),\n",
       " (277, -0.003177183704243252),\n",
       " (275, -0.0031908630753463376),\n",
       " (66, -0.0031927032843285016),\n",
       " (352, -0.003226415385839792),\n",
       " (192, -0.003269785270836866),\n",
       " (102, -0.003763651517659051),\n",
       " (169, -0.003938045695099185),\n",
       " (298, -0.0040010664676288),\n",
       " (37, -0.004005932103964877),\n",
       " (285, -0.004221541310978424),\n",
       " (67, -0.004232937749030498),\n",
       " (315, -0.004497467500598202),\n",
       " (317, -0.004533255439258133),\n",
       " (307, -0.004739465327429191),\n",
       " (5, -0.004867092143618967),\n",
       " (302, -0.005137242077182378),\n",
       " (248, -0.00532181759865812),\n",
       " (32, -0.005468657366711802),\n",
       " (355, -0.005658069420974948),\n",
       " (80, -0.005852481546364009),\n",
       " (328, -0.005853985677150475),\n",
       " (60, -0.005884229703550334),\n",
       " (50, -0.006911522428010097),\n",
       " (35, -0.007079457052536268),\n",
       " (68, -0.007138276064923068),\n",
       " (99, -0.007562095451630197),\n",
       " (40, -0.007923613439487227),\n",
       " (74, -0.008009207580827927),\n",
       " (122, -0.008192955281439615),\n",
       " (61, -0.008325862932953182),\n",
       " (31, -0.008452463197642738),\n",
       " (325, -0.008964967307575743),\n",
       " (114, -0.009069095268881054),\n",
       " (228, -0.009249190093466603),\n",
       " (81, -0.009326877868209923),\n",
       " (106, -0.009380913821712092),\n",
       " (222, -0.009439963220242199),\n",
       " (39, -0.009594375338672419),\n",
       " (57, -0.009850992535052821),\n",
       " (269, -0.01010827797103059),\n",
       " (104, -0.01016903486429825),\n",
       " (262, -0.01047937106746967),\n",
       " (92, -0.010514779629095467),\n",
       " (36, -0.01069695443946148),\n",
       " (211, -0.010951183495236678),\n",
       " (273, -0.010962971847230581),\n",
       " (85, -0.011071276274035546),\n",
       " (8, -0.011296324820073957),\n",
       " (291, -0.012170588378478979),\n",
       " (197, -0.012476786993476683),\n",
       " (13, -0.013055917657713531),\n",
       " (198, -0.01308545318443083),\n",
       " (348, -0.013113097715303295),\n",
       " (244, -0.013186804384945204),\n",
       " (2, -0.013227436771998237),\n",
       " (161, -0.013265737494108113),\n",
       " (320, -0.013705576500047114),\n",
       " (229, -0.013945809046882153),\n",
       " (300, -0.014291289130239972),\n",
       " (110, -0.014313338455902647),\n",
       " (235, -0.014675247732463937),\n",
       " (358, -0.014962062821866438),\n",
       " (249, -0.015439896917089845),\n",
       " (10, -0.01623204787005185),\n",
       " (330, -0.016358425175058682),\n",
       " (303, -0.01673283549439275),\n",
       " (29, -0.01688369204047754),\n",
       " (230, -0.016926297259987993),\n",
       " (109, -0.01748054704831983),\n",
       " (199, -0.01803871824508464),\n",
       " (146, -0.018067321390593666),\n",
       " (225, -0.01818323798499911),\n",
       " (329, -0.01838960462612714),\n",
       " (16, -0.018796186608867668),\n",
       " (105, -0.018824825411457833),\n",
       " (140, -0.018940836707880725),\n",
       " (265, -0.01897363560989278),\n",
       " (63, -0.019082402782493152),\n",
       " (232, -0.01918084502645602),\n",
       " (319, -0.019758545789922616),\n",
       " (323, -0.021270270221726402),\n",
       " (191, -0.02229009008594742),\n",
       " (335, -0.022456194917761907),\n",
       " (356, -0.022515447326180823),\n",
       " (26, -0.022898280338354744),\n",
       " (310, -0.023451909640882805),\n",
       " (212, -0.02346107791378281),\n",
       " (334, -0.023697003284681783),\n",
       " (279, -0.023738934759023715),\n",
       " (237, -0.024157157114617803),\n",
       " (3, -0.02443030019224096),\n",
       " (78, -0.024613304668066882),\n",
       " (360, -0.02571510067391428),\n",
       " (351, -0.02658372448241755),\n",
       " (338, -0.026646285706665936),\n",
       " (11, -0.02677968675007131),\n",
       " (343, -0.027632074233790136),\n",
       " (289, -0.029160674669652744),\n",
       " (190, -0.029642186537143907),\n",
       " (220, -0.02974606203210796),\n",
       " (268, -0.030677343905222035),\n",
       " (227, -0.031207069811588002),\n",
       " (213, -0.031322607690065826),\n",
       " (357, -0.03310096508264441),\n",
       " (318, -0.03336294319366632),\n",
       " (223, -0.03388053569246898),\n",
       " (97, -0.034204939453358514),\n",
       " (4, -0.03519166054798344),\n",
       " (195, -0.037000867398942906),\n",
       " (219, -0.03718949706311297),\n",
       " (281, -0.03777983527503869),\n",
       " (236, -0.03793429992373954),\n",
       " (12, -0.0384013908114725),\n",
       " (98, -0.0403206622441563),\n",
       " (260, -0.04183746604207212),\n",
       " (271, -0.04849286404195302),\n",
       " (96, -0.05093262693581356),\n",
       " (333, -0.051598597077479574),\n",
       " (21, -0.052029865422701924),\n",
       " (239, -0.053505105357780774),\n",
       " (56, -0.0574742858644166),\n",
       " (336, -0.05776491084192757),\n",
       " (159, -0.05917115607001072),\n",
       " (234, -0.059543941564309574),\n",
       " (210, -0.05977132742373094),\n",
       " (217, -0.06502593279054235),\n",
       " (214, -0.06601509041192904),\n",
       " (168, -0.06729824754958486),\n",
       " (0, -0.06936701272393865),\n",
       " (218, -0.07169976631633017),\n",
       " (185, -0.07633952173955884),\n",
       " (266, -0.07649359512895572),\n",
       " (283, -0.08395663448847314),\n",
       " (155, -0.08771075478462709),\n",
       " (158, -0.10834548520165431),\n",
       " (215, -0.11009630969307518),\n",
       " (332, -0.12458164690517361),\n",
       " (267, -0.12868637876576053),\n",
       " (203, -0.13011500232190548),\n",
       " (297, -0.1495112134717713),\n",
       " (342, -0.327795620319139),\n",
       " (364, -1.0200017849771579),\n",
       " (361, -2.0379410086968135),\n",
       " (362, -3.689669154583027)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(lr.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=10 .........\n",
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=10, score=0.6793289012051349, total=   1.8s\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=10 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=10, score=0.692053071228758, total=   1.7s\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=10 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=10, score=0.6642879000996424, total=   1.8s\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=15 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=15, score=0.6905024537115332, total=   2.5s\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=15 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=15, score=0.6881822988987676, total=   2.5s\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=15 .........\n",
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=15, score=0.6683329203558037, total=   2.5s\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=20, score=0.6878157776711931, total=   3.2s\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=20, score=0.6901658161333959, total=   3.3s\n",
      "[CV] max_features=175, min_samples_leaf=150, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=150, n_estimators=20, score=0.670370427246983, total=   3.3s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=10 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=10, score=0.6775437730152085, total=   1.7s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=10 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=10, score=0.6878218290435589, total=   1.7s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=10 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=10, score=0.6668784076311636, total=   1.7s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=15 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=15, score=0.6820936852676434, total=   2.4s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=15 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=15, score=0.6908931804285715, total=   2.5s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=15 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=15, score=0.6689760615402105, total=   2.5s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=20, score=0.6863911193364753, total=   3.2s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=20, score=0.6914340718175805, total=   3.2s\n",
      "[CV] max_features=175, min_samples_leaf=175, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=175, n_estimators=20, score=0.6687897284250167, total=   3.2s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=10 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=10, score=0.6784753911212558, total=   1.7s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=10 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=10, score=0.6912356827728785, total=   1.7s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=10 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=10, score=0.6677559248945041, total=   1.7s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=15 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=15, score=0.6802966409391815, total=   2.4s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=15 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=15, score=0.68696831895968, total=   2.5s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=15 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=15, score=0.6624487237341359, total=   2.4s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=20, score=0.6729698418795061, total=   3.2s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=20, score=0.6929186840573689, total=   3.1s\n",
      "[CV] max_features=175, min_samples_leaf=200, n_estimators=20 .........\n",
      "[CV]  max_features=175, min_samples_leaf=200, n_estimators=20, score=0.6599544087737437, total=   3.2s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=10, score=0.6832838329296597, total=   2.0s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=10, score=0.6891439872604482, total=   1.9s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=10, score=0.6753590571677676, total=   1.9s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=15, score=0.6862649735477719, total=   2.8s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=15, score=0.6859585928314643, total=   2.8s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=15, score=0.6716266094459507, total=   2.8s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=20 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=20, score=0.6866976866589792, total=   3.6s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=20 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=20, score=0.6948360094083645, total=   3.7s\n",
      "[CV] max_features=200, min_samples_leaf=150, n_estimators=20 .........\n",
      "[CV]  max_features=200, min_samples_leaf=150, n_estimators=20, score=0.6706769477542633, total=   3.6s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=10, score=0.6803085570777171, total=   1.9s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=10, score=0.6915783717233818, total=   2.0s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=10, score=0.671542467607125, total=   2.0s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=15, score=0.6853934959529915, total=   2.8s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=15, score=0.6921372306232924, total=   2.7s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=15, score=0.6673953093964198, total=   2.7s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=20 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=20, score=0.6872266619094527, total=   3.6s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=20 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=20, score=0.6935978239798132, total=   3.6s\n",
      "[CV] max_features=200, min_samples_leaf=175, n_estimators=20 .........\n",
      "[CV]  max_features=200, min_samples_leaf=175, n_estimators=20, score=0.6681826327938711, total=   3.5s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=10, score=0.6823582661959784, total=   1.8s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=10, score=0.6848945909581514, total=   1.9s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=10 .........\n",
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=10, score=0.672329737682752, total=   1.8s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=15, score=0.6799359844777766, total=   2.6s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=15, score=0.6806633487729523, total=   2.7s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=15 .........\n",
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=15, score=0.6656462735749782, total=   2.7s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=20 .........\n",
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=20, score=0.6850088206083191, total=   3.5s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=20 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=20, score=0.6929967920795372, total=   3.5s\n",
      "[CV] max_features=200, min_samples_leaf=200, n_estimators=20 .........\n",
      "[CV]  max_features=200, min_samples_leaf=200, n_estimators=20, score=0.6655921785841743, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'max_features': [175, 200], 'n_estimators': [10, 15, 20], 'min_samples_leaf': [150, 175, 200]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(roc_auc_score), verbose=5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#scoring=make_scorer(roc_auc_score)\n",
    "\n",
    "param_grid = [{'max_features':[175,200], 'n_estimators':[10,15,20], 'min_samples_leaf':[150,175,200]}]\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "            param_grid, cv=3, scoring=make_scorer(roc_auc_score), \n",
    "            verbose=5\n",
    ")\n",
    "rf_grid_search.fit(X_train_h, Y_train_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785570461047503 {'max_features': 175, 'min_samples_leaf': 150, 'n_estimators': 10}\n",
      "0.6823396384891638 {'max_features': 175, 'min_samples_leaf': 150, 'n_estimators': 15}\n",
      "0.6827843740873832 {'max_features': 175, 'min_samples_leaf': 150, 'n_estimators': 20}\n",
      "0.677414981454461 {'max_features': 175, 'min_samples_leaf': 175, 'n_estimators': 10}\n",
      "0.680654654405189 {'max_features': 175, 'min_samples_leaf': 175, 'n_estimators': 15}\n",
      "0.6822053698825022 {'max_features': 175, 'min_samples_leaf': 175, 'n_estimators': 20}\n",
      "0.6791560033538183 {'max_features': 175, 'min_samples_leaf': 200, 'n_estimators': 10}\n",
      "0.6765716454808399 {'max_features': 175, 'min_samples_leaf': 200, 'n_estimators': 15}\n",
      "0.6752814314443205 {'max_features': 175, 'min_samples_leaf': 200, 'n_estimators': 20}\n",
      "0.6825958397716648 {'max_features': 200, 'min_samples_leaf': 150, 'n_estimators': 10}\n",
      "0.6812836774932842 {'max_features': 200, 'min_samples_leaf': 150, 'n_estimators': 15}\n",
      "0.6840706106467923 {'max_features': 200, 'min_samples_leaf': 150, 'n_estimators': 20}\n",
      "0.6811434160282187 {'max_features': 200, 'min_samples_leaf': 175, 'n_estimators': 10}\n",
      "0.68164243326663 {'max_features': 200, 'min_samples_leaf': 175, 'n_estimators': 15}\n",
      "0.6830028111148563 {'max_features': 200, 'min_samples_leaf': 175, 'n_estimators': 20}\n",
      "0.6798610876414479 {'max_features': 200, 'min_samples_leaf': 200, 'n_estimators': 10}\n",
      "0.67541549114296 {'max_features': 200, 'min_samples_leaf': 200, 'n_estimators': 15}\n",
      "0.6811997252596551 {'max_features': 200, 'min_samples_leaf': 200, 'n_estimators': 20}\n",
      "Best: {'max_features': 200, 'min_samples_leaf': 150, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "cvres = rf_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(rf_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8445568272557892\n",
      "ROC: 0.8518840579710145\n",
      "PPV: 0.8748499399759904\n",
      "NPV: 0.6070588235294118\n",
      "Sensitivity: 0.9458144062297209\n",
      "Specificity: 0.38222222222222224\n",
      "G-Mean: 0.6012580844852863\n",
      "Confusion matrix:\n",
      "[[ 258  417]\n",
      " [ 167 2915]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=20, min_samples_leaf=300, max_features=225)\n",
    "rf_clf.fit(X_train_h, Y_train_h)\n",
    "results(rf_clf, X_test_h, Y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(187, 0.5697810360268841),\n",
       " (277, 0.12129826161643897),\n",
       " (297, 0.07440201343781659),\n",
       " (298, 0.0646508076851262),\n",
       " (233, 0.05641264141965241),\n",
       " (266, 0.04393150533278482),\n",
       " (300, 0.021550127872390086),\n",
       " (102, 0.010357623284759672),\n",
       " (276, 0.008565160114061339),\n",
       " (170, 0.007650877963974014),\n",
       " (211, 0.007505700745796593),\n",
       " (275, 0.002222382464448982),\n",
       " (267, 0.0021908561452082614),\n",
       " (41, 0.0009972427842070656),\n",
       " (19, 0.0009095025274065983),\n",
       " (101, 0.0007702506440262185),\n",
       " (1, 0.0007457322059716467),\n",
       " (218, 0.0006380097189094962),\n",
       " (248, 0.0006366913920819013),\n",
       " (104, 0.0005872028224967013),\n",
       " (144, 0.0005664631453068588),\n",
       " (299, 0.0004599625276868865),\n",
       " (7, 0.00036093351322826866),\n",
       " (133, 0.0003598373306445186),\n",
       " (292, 0.0002711136152987014),\n",
       " (213, 0.00026975087245193223),\n",
       " (99, 0.0002462104498946162),\n",
       " (137, 0.00019970244030970163),\n",
       " (251, 0.0001726802777839547),\n",
       " (203, 0.00015843505275603084),\n",
       " (4, 0.00013910323714702317),\n",
       " (278, 0.00013665999426966976),\n",
       " (169, 9.945334980593786e-05),\n",
       " (226, 9.628595338535283e-05),\n",
       " (212, 9.50088050976116e-05),\n",
       " (126, 9.365863276786655e-05),\n",
       " (229, 7.611407185601277e-05),\n",
       " (290, 7.022622778221487e-05),\n",
       " (274, 5.7979131689860305e-05),\n",
       " (222, 5.53933017842334e-05),\n",
       " (15, 5.2713355233025126e-05),\n",
       " (0, 5.001356332509501e-05),\n",
       " (219, 3.803359565663539e-05),\n",
       " (121, 3.687198571549926e-05),\n",
       " (244, 1.1544129116710868e-05),\n",
       " (60, 6.090345425962038e-06),\n",
       " (295, 6.0854859498227716e-06),\n",
       " (8, 5.368588354678581e-06),\n",
       " (215, 2.2041296478052724e-06),\n",
       " (50, 1.6965927115511634e-06),\n",
       " (246, 7.800934743139891e-07),\n",
       " (2, 0.0),\n",
       " (3, 0.0),\n",
       " (5, 0.0),\n",
       " (6, 0.0),\n",
       " (9, 0.0),\n",
       " (10, 0.0),\n",
       " (11, 0.0),\n",
       " (12, 0.0),\n",
       " (13, 0.0),\n",
       " (14, 0.0),\n",
       " (16, 0.0),\n",
       " (17, 0.0),\n",
       " (18, 0.0),\n",
       " (20, 0.0),\n",
       " (21, 0.0),\n",
       " (22, 0.0),\n",
       " (23, 0.0),\n",
       " (24, 0.0),\n",
       " (25, 0.0),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (28, 0.0),\n",
       " (29, 0.0),\n",
       " (30, 0.0),\n",
       " (31, 0.0),\n",
       " (32, 0.0),\n",
       " (33, 0.0),\n",
       " (34, 0.0),\n",
       " (35, 0.0),\n",
       " (36, 0.0),\n",
       " (37, 0.0),\n",
       " (38, 0.0),\n",
       " (39, 0.0),\n",
       " (40, 0.0),\n",
       " (42, 0.0),\n",
       " (43, 0.0),\n",
       " (44, 0.0),\n",
       " (45, 0.0),\n",
       " (46, 0.0),\n",
       " (47, 0.0),\n",
       " (48, 0.0),\n",
       " (49, 0.0),\n",
       " (51, 0.0),\n",
       " (52, 0.0),\n",
       " (53, 0.0),\n",
       " (54, 0.0),\n",
       " (55, 0.0),\n",
       " (56, 0.0),\n",
       " (57, 0.0),\n",
       " (58, 0.0),\n",
       " (59, 0.0),\n",
       " (61, 0.0),\n",
       " (62, 0.0),\n",
       " (63, 0.0),\n",
       " (64, 0.0),\n",
       " (65, 0.0),\n",
       " (66, 0.0),\n",
       " (67, 0.0),\n",
       " (68, 0.0),\n",
       " (69, 0.0),\n",
       " (70, 0.0),\n",
       " (71, 0.0),\n",
       " (72, 0.0),\n",
       " (73, 0.0),\n",
       " (74, 0.0),\n",
       " (75, 0.0),\n",
       " (76, 0.0),\n",
       " (77, 0.0),\n",
       " (78, 0.0),\n",
       " (79, 0.0),\n",
       " (80, 0.0),\n",
       " (81, 0.0),\n",
       " (82, 0.0),\n",
       " (83, 0.0),\n",
       " (84, 0.0),\n",
       " (85, 0.0),\n",
       " (86, 0.0),\n",
       " (87, 0.0),\n",
       " (88, 0.0),\n",
       " (89, 0.0),\n",
       " (90, 0.0),\n",
       " (91, 0.0),\n",
       " (92, 0.0),\n",
       " (93, 0.0),\n",
       " (94, 0.0),\n",
       " (95, 0.0),\n",
       " (96, 0.0),\n",
       " (97, 0.0),\n",
       " (98, 0.0),\n",
       " (100, 0.0),\n",
       " (103, 0.0),\n",
       " (105, 0.0),\n",
       " (106, 0.0),\n",
       " (107, 0.0),\n",
       " (108, 0.0),\n",
       " (109, 0.0),\n",
       " (110, 0.0),\n",
       " (111, 0.0),\n",
       " (112, 0.0),\n",
       " (113, 0.0),\n",
       " (114, 0.0),\n",
       " (115, 0.0),\n",
       " (116, 0.0),\n",
       " (117, 0.0),\n",
       " (118, 0.0),\n",
       " (119, 0.0),\n",
       " (120, 0.0),\n",
       " (122, 0.0),\n",
       " (123, 0.0),\n",
       " (124, 0.0),\n",
       " (125, 0.0),\n",
       " (127, 0.0),\n",
       " (128, 0.0),\n",
       " (129, 0.0),\n",
       " (130, 0.0),\n",
       " (131, 0.0),\n",
       " (132, 0.0),\n",
       " (134, 0.0),\n",
       " (135, 0.0),\n",
       " (136, 0.0),\n",
       " (138, 0.0),\n",
       " (139, 0.0),\n",
       " (140, 0.0),\n",
       " (141, 0.0),\n",
       " (142, 0.0),\n",
       " (143, 0.0),\n",
       " (145, 0.0),\n",
       " (146, 0.0),\n",
       " (147, 0.0),\n",
       " (148, 0.0),\n",
       " (149, 0.0),\n",
       " (150, 0.0),\n",
       " (151, 0.0),\n",
       " (152, 0.0),\n",
       " (153, 0.0),\n",
       " (154, 0.0),\n",
       " (155, 0.0),\n",
       " (156, 0.0),\n",
       " (157, 0.0),\n",
       " (158, 0.0),\n",
       " (159, 0.0),\n",
       " (160, 0.0),\n",
       " (161, 0.0),\n",
       " (162, 0.0),\n",
       " (163, 0.0),\n",
       " (164, 0.0),\n",
       " (165, 0.0),\n",
       " (166, 0.0),\n",
       " (167, 0.0),\n",
       " (168, 0.0),\n",
       " (171, 0.0),\n",
       " (172, 0.0),\n",
       " (173, 0.0),\n",
       " (174, 0.0),\n",
       " (175, 0.0),\n",
       " (176, 0.0),\n",
       " (177, 0.0),\n",
       " (178, 0.0),\n",
       " (179, 0.0),\n",
       " (180, 0.0),\n",
       " (181, 0.0),\n",
       " (182, 0.0),\n",
       " (183, 0.0),\n",
       " (184, 0.0),\n",
       " (185, 0.0),\n",
       " (186, 0.0),\n",
       " (188, 0.0),\n",
       " (189, 0.0),\n",
       " (190, 0.0),\n",
       " (191, 0.0),\n",
       " (192, 0.0),\n",
       " (193, 0.0),\n",
       " (194, 0.0),\n",
       " (195, 0.0),\n",
       " (196, 0.0),\n",
       " (197, 0.0),\n",
       " (198, 0.0),\n",
       " (199, 0.0),\n",
       " (200, 0.0),\n",
       " (201, 0.0),\n",
       " (202, 0.0),\n",
       " (204, 0.0),\n",
       " (205, 0.0),\n",
       " (206, 0.0),\n",
       " (207, 0.0),\n",
       " (208, 0.0),\n",
       " (209, 0.0),\n",
       " (210, 0.0),\n",
       " (214, 0.0),\n",
       " (216, 0.0),\n",
       " (217, 0.0),\n",
       " (220, 0.0),\n",
       " (221, 0.0),\n",
       " (223, 0.0),\n",
       " (224, 0.0),\n",
       " (225, 0.0),\n",
       " (227, 0.0),\n",
       " (228, 0.0),\n",
       " (230, 0.0),\n",
       " (231, 0.0),\n",
       " (232, 0.0),\n",
       " (234, 0.0),\n",
       " (235, 0.0),\n",
       " (236, 0.0),\n",
       " (237, 0.0),\n",
       " (238, 0.0),\n",
       " (239, 0.0),\n",
       " (240, 0.0),\n",
       " (241, 0.0),\n",
       " (242, 0.0),\n",
       " (243, 0.0),\n",
       " (245, 0.0),\n",
       " (247, 0.0),\n",
       " (249, 0.0),\n",
       " (250, 0.0),\n",
       " (252, 0.0),\n",
       " (253, 0.0),\n",
       " (254, 0.0),\n",
       " (255, 0.0),\n",
       " (256, 0.0),\n",
       " (257, 0.0),\n",
       " (258, 0.0),\n",
       " (259, 0.0),\n",
       " (260, 0.0),\n",
       " (261, 0.0),\n",
       " (262, 0.0),\n",
       " (263, 0.0),\n",
       " (264, 0.0),\n",
       " (265, 0.0),\n",
       " (268, 0.0),\n",
       " (269, 0.0),\n",
       " (270, 0.0),\n",
       " (271, 0.0),\n",
       " (272, 0.0),\n",
       " (273, 0.0),\n",
       " (279, 0.0),\n",
       " (280, 0.0),\n",
       " (281, 0.0),\n",
       " (282, 0.0),\n",
       " (283, 0.0),\n",
       " (284, 0.0),\n",
       " (285, 0.0),\n",
       " (286, 0.0),\n",
       " (287, 0.0),\n",
       " (288, 0.0),\n",
       " (289, 0.0),\n",
       " (291, 0.0),\n",
       " (293, 0.0),\n",
       " (294, 0.0),\n",
       " (296, 0.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(rf_clf.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(rf_grid_search, X_test_h, Y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, max_features=20, min_samples_leaf=50, verbose=3)\n",
    "rf_clf.fit(X_train_m, Y_train_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(rf_clf, X_test_m, Y_test_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(kernel=\"rbf\", gamma=5, C=0.1, verbose=3)\n",
    "svm_clf.fit(X_train_h, Y_train_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(svm_clf, X_test_h, Y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler(feature_range=(-1,1)).fit(X_train_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_clf = LinearSVC(C=.01)\n",
    "svm_clf.fit(X_train_h, Y_train_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8514772424807027\n",
      "ROC: 0.6763354723964717\n",
      "PPV: 0.878978978978979\n",
      "NPV: 0.6370023419203747\n",
      "Sensitivity: 0.9497079818299805\n",
      "Specificity: 0.40296296296296297\n",
      "G-Mean: 0.6186252034210898\n",
      "Confusion matrix:\n",
      "[[ 272  403]\n",
      " [ 155 2927]]\n"
     ]
    }
   ],
   "source": [
    "results(svm_clf, X_test_h, Y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, 0.12191538013950175),\n",
       " (187, 0.0848940088933371),\n",
       " (299, 0.07784953698289407),\n",
       " (123, 0.051141067770208916),\n",
       " (269, 0.046320907747084535),\n",
       " (40, 0.04453483168525132),\n",
       " (35, 0.04364683474237397),\n",
       " (126, 0.04076491288364893),\n",
       " (266, 0.03556333886225712),\n",
       " (121, 0.030437792079564308),\n",
       " (91, 0.029007493232082925),\n",
       " (59, 0.026652221677057625),\n",
       " (133, 0.025239734400257566),\n",
       " (265, 0.024098400561465602),\n",
       " (108, 0.023748322233822162),\n",
       " (231, 0.023445893376109448),\n",
       " (211, 0.022503990963415137),\n",
       " (280, 0.021375114922663554),\n",
       " (295, 0.020928129674443033),\n",
       " (278, 0.02081058063150811),\n",
       " (168, 0.020174917357648432),\n",
       " (83, 0.020145322095191327),\n",
       " (9, 0.020023630005344604),\n",
       " (190, 0.01975800900099815),\n",
       " (100, 0.019735476855558633),\n",
       " (225, 0.019253653417910892),\n",
       " (55, 0.01845265069850628),\n",
       " (185, 0.018381599239679577),\n",
       " (114, 0.017952663807103895),\n",
       " (87, 0.01770286756497439),\n",
       " (116, 0.016202596484654955),\n",
       " (125, 0.015790515652467585),\n",
       " (88, 0.015729191868451304),\n",
       " (274, 0.015636927329712166),\n",
       " (82, 0.015438999440021934),\n",
       " (71, 0.01535156183873272),\n",
       " (74, 0.015235200338309182),\n",
       " (143, 0.01509709496506096),\n",
       " (7, 0.015048766776656045),\n",
       " (57, 0.014988728086092354),\n",
       " (230, 0.01469910538036549),\n",
       " (206, 0.01417781077533319),\n",
       " (139, 0.013738975516197445),\n",
       " (170, 0.01360681738576583),\n",
       " (247, 0.013446214566394768),\n",
       " (29, 0.013331116372669038),\n",
       " (248, 0.013324215269624923),\n",
       " (101, 0.013264674302554328),\n",
       " (66, 0.013167613673387526),\n",
       " (124, 0.013007521426220246),\n",
       " (223, 0.012580075238826594),\n",
       " (48, 0.012520522255365178),\n",
       " (106, 0.012512931694255927),\n",
       " (36, 0.012365493925311506),\n",
       " (84, 0.012356833935647545),\n",
       " (229, 0.012335449137793329),\n",
       " (262, 0.012304114232379109),\n",
       " (110, 0.012032613410356004),\n",
       " (177, 0.011940893931946249),\n",
       " (167, 0.011940072134753824),\n",
       " (19, 0.011835765664755823),\n",
       " (20, 0.011601299750558928),\n",
       " (259, 0.011449248495718328),\n",
       " (275, 0.011291162496876221),\n",
       " (188, 0.011152344200175912),\n",
       " (249, 0.010863526834033953),\n",
       " (184, 0.010785628858120195),\n",
       " (214, 0.010666286002706818),\n",
       " (17, 0.010629442133110099),\n",
       " (252, 0.01056160733138127),\n",
       " (140, 0.010515398194211394),\n",
       " (115, 0.010246880107765014),\n",
       " (216, 0.010105830248996901),\n",
       " (15, 0.009825541517140437),\n",
       " (6, 0.009738171878230851),\n",
       " (270, 0.00958993356375503),\n",
       " (5, 0.009362941998868685),\n",
       " (210, 0.008984620522870343),\n",
       " (222, 0.008605025791850674),\n",
       " (189, 0.008525603398541881),\n",
       " (89, 0.008525516915029152),\n",
       " (246, 0.008489726705992085),\n",
       " (241, 0.008419941625043498),\n",
       " (235, 0.008419941625040195),\n",
       " (251, 0.008383552287304419),\n",
       " (239, 0.008267929946551462),\n",
       " (38, 0.007706427639781086),\n",
       " (289, 0.0076073849982727405),\n",
       " (127, 0.0074552293075036535),\n",
       " (81, 0.007417965019827383),\n",
       " (263, 0.0073642398701036695),\n",
       " (117, 0.007352479706257855),\n",
       " (232, 0.007346471711487909),\n",
       " (43, 0.0073122674051353765),\n",
       " (293, 0.006884007383776031),\n",
       " (118, 0.006703367598829381),\n",
       " (162, 0.006693550315669875),\n",
       " (242, 0.006656253023273742),\n",
       " (39, 0.00665625302327298),\n",
       " (79, 0.006515811889366056),\n",
       " (53, 0.0063985118828206785),\n",
       " (67, 0.006361157038090823),\n",
       " (288, 0.006219342443883953),\n",
       " (85, 0.006161626145444248),\n",
       " (224, 0.006134842724505669),\n",
       " (131, 0.005953445659978669),\n",
       " (54, 0.005506696163332103),\n",
       " (287, 0.005343671898611642),\n",
       " (255, 0.005170139976523196),\n",
       " (159, 0.005155758945110878),\n",
       " (243, 0.005155758945110371),\n",
       " (132, 0.0051557589451083985),\n",
       " (195, 0.005155758945107042),\n",
       " (107, 0.0051208470766808),\n",
       " (237, 0.0049185716735088356),\n",
       " (254, 0.004730192198408126),\n",
       " (178, 0.004727475647545533),\n",
       " (294, 0.004627289368878754),\n",
       " (73, 0.004514362619065917),\n",
       " (119, 0.004351668154713807),\n",
       " (256, 0.00420959730670298),\n",
       " (96, 0.004209597306701928),\n",
       " (37, 0.0042095973067015685),\n",
       " (191, 0.004209597306701239),\n",
       " (95, 0.004209597306701078),\n",
       " (194, 0.004209597306700979),\n",
       " (145, 0.0042095973067006204),\n",
       " (64, 0.004209597306699965),\n",
       " (113, 0.0040407806841778705),\n",
       " (165, 0.00395279479341968),\n",
       " (49, 0.003808175653276921),\n",
       " (257, 0.0037841812513715184),\n",
       " (180, 0.003441157838753503),\n",
       " (13, 0.003338667408924706),\n",
       " (238, 0.003115846600681233),\n",
       " (221, 0.003018021327722344),\n",
       " (296, 0.0030136607050175895),\n",
       " (258, 0.0030046848598365666),\n",
       " (97, 0.0029765907903877417),\n",
       " (98, 0.0029765907903872915),\n",
       " (28, 0.002976590790387222),\n",
       " (33, 0.0029765907903868726),\n",
       " (181, 0.002976590790386744),\n",
       " (62, 0.002976590790386445),\n",
       " (93, 0.0029765907903863903),\n",
       " (80, 0.002976590790386337),\n",
       " (72, 0.0029765907903855147),\n",
       " (78, 0.0029765907903855056),\n",
       " (147, 0.002976590790385249),\n",
       " (146, 0.0029765907903850056),\n",
       " (45, 0.0029765907903846677),\n",
       " (92, 0.002976590790384601),\n",
       " (86, 0.0029765907903844977),\n",
       " (129, 0.002976590790383844),\n",
       " (75, 0.002976590790383322),\n",
       " (42, 0.0029765907903832618),\n",
       " (24, 0.002751096667705972),\n",
       " (281, 0.0026668091888831726),\n",
       " (244, 0.0026374597238694878),\n",
       " (271, 0.002337720158813972),\n",
       " (197, 0.002045179206326709),\n",
       " (128, 0.001983378462849411),\n",
       " (4, 0.0018238340463393636),\n",
       " (193, 0.001700042497642703),\n",
       " (104, 0.0016724578073171435),\n",
       " (105, 0.0016654520923345796),\n",
       " (264, 0.0014007555007836345),\n",
       " (172, 0.0012993971092834988),\n",
       " (220, 0.0012686319271601376),\n",
       " (212, 0.0012441767513157555),\n",
       " (260, 0.0012142939026927107),\n",
       " (122, 0.0010462709633116793),\n",
       " (136, 0.0008436708483153361),\n",
       " (215, 0.0006678190309569303),\n",
       " (1, 0.0005934338656449962),\n",
       " (26, 0.0004879666878382038),\n",
       " (148, 0.00022948088211639686),\n",
       " (234, 0.0001356498458414453),\n",
       " (22, 0.0),\n",
       " (27, 0.0),\n",
       " (44, 0.0),\n",
       " (51, 0.0),\n",
       " (120, 0.0),\n",
       " (236, 0.0),\n",
       " (2, -0.0001268634147954855),\n",
       " (240, -0.0001569344598890347),\n",
       " (283, -0.0002860088067699315),\n",
       " (16, -0.0003753111899778232),\n",
       " (134, -0.0008317072820662425),\n",
       " (276, -0.0009001017753040269),\n",
       " (218, -0.0009880070928527953),\n",
       " (65, -0.0015037405057726516),\n",
       " (47, -0.0016607065439692666),\n",
       " (52, -0.0018064300345806594),\n",
       " (31, -0.002225085313300749),\n",
       " (261, -0.0022471276201462436),\n",
       " (182, -0.0023907895857825778),\n",
       " (111, -0.0026411005710743835),\n",
       " (176, -0.002672228780261119),\n",
       " (166, -0.0027243519869316135),\n",
       " (151, -0.0028139775029380437),\n",
       " (291, -0.0030223287403063695),\n",
       " (152, -0.0030810975204176192),\n",
       " (213, -0.0034992823168569975),\n",
       " (3, -0.0037066597177221614),\n",
       " (153, -0.0037678621108795224),\n",
       " (10, -0.004579731179899732),\n",
       " (286, -0.004645748698952205),\n",
       " (250, -0.004704917473084605),\n",
       " (198, -0.004811878649160725),\n",
       " (69, -0.004860209470666831),\n",
       " (174, -0.004872544764360889),\n",
       " (142, -0.004908469059171138),\n",
       " (76, -0.005121485748807974),\n",
       " (90, -0.00534406878130238),\n",
       " (46, -0.005466456398036403),\n",
       " (279, -0.005727971085875662),\n",
       " (282, -0.005740348519183248),\n",
       " (0, -0.006479209867640411),\n",
       " (284, -0.006539556513699938),\n",
       " (209, -0.006676155481437732),\n",
       " (290, -0.0067041243571716235),\n",
       " (186, -0.007038789489786574),\n",
       " (285, -0.007079498913164652),\n",
       " (217, -0.007304048537320311),\n",
       " (70, -0.007375105966183742),\n",
       " (12, -0.007562144139268278),\n",
       " (208, -0.007994202506334659),\n",
       " (137, -0.008059179635399922),\n",
       " (175, -0.008163786077102912),\n",
       " (135, -0.008359444044176538),\n",
       " (18, -0.008470471710610028),\n",
       " (11, -0.00860899842125312),\n",
       " (226, -0.00886088000541276),\n",
       " (227, -0.009184791409245935),\n",
       " (60, -0.009472209262642018),\n",
       " (141, -0.009682123078078383),\n",
       " (171, -0.00978617332657027),\n",
       " (228, -0.010362779850534012),\n",
       " (245, -0.01037186083794916),\n",
       " (58, -0.010645609403924944),\n",
       " (32, -0.010745783379975775),\n",
       " (14, -0.011202574454744336),\n",
       " (157, -0.011687791603363843),\n",
       " (199, -0.01173292390319229),\n",
       " (173, -0.011871450575406116),\n",
       " (292, -0.012384668153927691),\n",
       " (200, -0.012922909881955153),\n",
       " (63, -0.01335584914894354),\n",
       " (160, -0.013392273767732115),\n",
       " (161, -0.013667857235843862),\n",
       " (138, -0.014044250649316728),\n",
       " (253, -0.01409630902985278),\n",
       " (205, -0.014372838098849575),\n",
       " (272, -0.014675880244910554),\n",
       " (34, -0.014681298893807149),\n",
       " (61, -0.014700435000003386),\n",
       " (94, -0.014889138964364276),\n",
       " (8, -0.015125785318806784),\n",
       " (99, -0.01563692732970662),\n",
       " (21, -0.015647626568423962),\n",
       " (68, -0.01595412011995951),\n",
       " (201, -0.01595890898403005),\n",
       " (103, -0.017022442055235912),\n",
       " (112, -0.01742102154985907),\n",
       " (56, -0.017556486830493413),\n",
       " (109, -0.017867975582585),\n",
       " (183, -0.018048218554478135),\n",
       " (150, -0.019176223125028646),\n",
       " (192, -0.019551257420205786),\n",
       " (23, -0.020146219778678368),\n",
       " (156, -0.020534776178156966),\n",
       " (149, -0.020970844513292376),\n",
       " (268, -0.021127173449861744),\n",
       " (204, -0.021991365950734247),\n",
       " (179, -0.02276983452755153),\n",
       " (207, -0.02322959121265106),\n",
       " (30, -0.024073524763128528),\n",
       " (164, -0.024428562363369082),\n",
       " (41, -0.02448408657740961),\n",
       " (219, -0.026507118125787647),\n",
       " (163, -0.027418909492562243),\n",
       " (130, -0.028736846670883432),\n",
       " (196, -0.029565488048752153),\n",
       " (158, -0.030140167342885035),\n",
       " (25, -0.030176120629370872),\n",
       " (77, -0.03167432165939632),\n",
       " (277, -0.031687654199369635),\n",
       " (169, -0.03169373648089491),\n",
       " (273, -0.032225332880924495),\n",
       " (102, -0.03281412903826384),\n",
       " (267, -0.033536521362843096),\n",
       " (154, -0.03516644973780057),\n",
       " (155, -0.03535398737819879),\n",
       " (144, -0.03759270070498391),\n",
       " (233, -0.039824421512022604),\n",
       " (202, -0.04786182410120283),\n",
       " (203, -0.0816911080812095),\n",
       " (300, -0.160603977408472),\n",
       " (297, -0.40674200901922086),\n",
       " (298, -1.2842795255265267)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(svm_clf.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=225, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=300, min_samples_split=2,\n",
       "            min_wei...r='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('nb', GaussianNB(priors=None))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf1 = RandomForestClassifier(n_estimators=20, min_samples_leaf=300, max_features=225)\n",
    "clf2 = LogisticRegression(C=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[\n",
    "    ('rf', clf1), ('lr', clf2), ('nb', clf3)\n",
    "], voting='soft')\n",
    "eclf.fit(X_train_h, Y_train_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8261911099281342\n",
      "ROC: 0.8564116614992668\n",
      "PPV: 0.9305210918114144\n",
      "NPV: 0.5117521367521367\n",
      "Sensitivity: 0.8517196625567813\n",
      "Specificity: 0.7096296296296296\n",
      "G-Mean: 0.7774352118912816\n",
      "Confusion matrix:\n",
      "[[ 479  196]\n",
      " [ 457 2625]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "results(eclf, X_test_h, Y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
