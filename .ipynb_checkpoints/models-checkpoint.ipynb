{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = \"hispanic\"\n",
    "#race = \"white\"\n",
    "#race = \"mixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../Data/' + race + '/X.npy')\n",
    "Y2 = np.load('../Data/' + race + '/Y2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(X, Y):\n",
    "    # shuffle\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(len(X))\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "    \n",
    "    #X = X[:size_hispanic]\n",
    "    #Y = Y[:size_hispanic]\n",
    "\n",
    "    # split into training and test sets\n",
    "    TEST_SET_SIZE = int(0.1*len(Y))\n",
    "    X_train, X_test = X[:-TEST_SET_SIZE], X[-TEST_SET_SIZE:]\n",
    "    Y_train, Y_test = Y[:-TEST_SET_SIZE].astype(int), Y[-TEST_SET_SIZE:].astype(int)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(X, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247993, 365)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "Fit scaler based on training data, then transform both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# feature scaling: scale features based on training data only\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def feature_scale(X_train, X_test):\n",
    "    \n",
    "    mm_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    X_train[:,:-4] = mm_scaler.fit_transform(X_train[:,:-4])\n",
    "    X_test[:,:-4] = mm_scaler.transform(X_test[:,:-4])\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train[:,-4:] = std_scaler.fit_transform(X_train[:,-4:])\n",
    "    X_test[:,-4:] = std_scaler.transform(X_test[:,-4:])\n",
    "    return X_train, X_test\n",
    "    \n",
    "    #mm_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    #X_train[:,-4:] = mm_scaler.fit_transform(X_train[:,-4:])\n",
    "    #X_test[:,-4:] = mm_scaler.transform(X_test[:,-4:])\n",
    "    \n",
    "    #std_scaler = StandardScaler()\n",
    "    #X_train[:,:-4] = std_scaler.fit_transform(X_train[:,:-4])\n",
    "    #X_test[:,:-4] = std_scaler.transform(X_test[:,:-4])\n",
    "    #return X_train, X_test\n",
    "\n",
    "X_train, X_test = feature_scale(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def results(classifier):\n",
    "    Y_pred_test = classifier.predict(X_test)\n",
    "    print(\"Test accuracy score: \" + str(accuracy_score(Y_test.astype(int), Y_pred_test)))\n",
    "    print(\"ROC: \" + str(roc_auc_score(Y_test, classifier.predict_proba(X_test)[:,1])))\n",
    "    #print(\"ROC: \" + str(roc_auc_score(Y_test, Y_pred_test)))\n",
    "    matrix = confusion_matrix(Y_test.astype(int), Y_pred_test)\n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    ppv = tp/(tp+fp)\n",
    "    npv = tn/(tn+fn)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    g_mean = np.sqrt(sensitivity*specificity)\n",
    "    print(\"PPV: \" + str(ppv))\n",
    "    print(\"NPV: \" + str(npv))\n",
    "    print(\"Sensitivity: \" + str(sensitivity))\n",
    "    print(\"Specificity: \" + str(specificity))\n",
    "    print(\"G-Mean: \" + str(g_mean))\n",
    "    print(\"Confusion matrix:\\n\" + str(matrix))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('white_codes.pkl', 'rb') as f_w:\n",
    "    white_codes = pickle.load(f_w)\n",
    "with open('hispanic_codes.pkl', 'rb') as f_h:\n",
    "    hispanic_codes = pickle.load(f_h)\n",
    "with open('mixed_codes.pkl', 'rb')  as f_m:\n",
    "    mixed_codes = pickle.load(f_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_rank(array):\n",
    "    codes = None\n",
    "    if race == \"white\":\n",
    "        codes = white_codes\n",
    "    elif race == \"hispanic\":\n",
    "        codes = hispanic_codes\n",
    "    elif race == \"mixed\":\n",
    "        codes = mixed_codes\n",
    "        \n",
    "    array = np.abs(array)\n",
    "    \n",
    "    ranking = {}\n",
    "    ranking['tumsiz'] = array[-1]\n",
    "    ranking['maligcount'] = array[-2]\n",
    "    ranking['eod10_pn'] = array[-3]\n",
    "    ranking['age_dx'] = array[-4]\n",
    "    \n",
    "    for key, val in codes.items():\n",
    "        varname = key[1]\n",
    "        start_idx = key[2]\n",
    "        end_idx = start_idx + len(val)\n",
    "        ranking[varname] = np.sum(array[start_idx:end_idx])\n",
    "    \n",
    "    d_view = [(name, score) for name,score in ranking.items()]\n",
    "    d_view.sort(key=lambda x:x[1], reverse=True)\n",
    "    for rank, pair in enumerate(d_view, 1):\n",
    "        print(rank, pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hispanic'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# min_sample_split: 300,400\n",
    "# min_samples_leaf: 200\n",
    "# max_depth: 130\n",
    "# min_weight_fraction_leaf: .01\n",
    "param_grid = [{'max_depth':[40,50,60], 'min_samples_leaf':[250,260,270,280,290]}]\n",
    "tree_clf_reg = DecisionTreeClassifier()\n",
    "dt_grid_search = GridSearchCV(tree_clf_reg, param_grid, cv=3, scoring=make_scorer(roc_auc_score), verbose=3)\n",
    "dt_grid_search.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = dt_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(dt_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(dt_grid_search, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_h = DecisionTreeClassifier(max_features=200, min_samples_leaf=150)\n",
    "tree_clf_h.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(tree_clf_h, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(tree_clf_h.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(tree_clf_h.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(knn_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = [{'C':[.01, .1, .75, 1, 1.5, 2]}]\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3, \n",
    "                              scoring=make_scorer(roc_auc_score), verbose=5\n",
    "                             )\n",
    "lr_grid_search.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = lr_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(lr_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(lr_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8103723597299848\n",
      "ROC: 0.8714802329430767\n",
      "PPV: 0.9395257326291809\n",
      "NPV: 0.5076456310679611\n",
      "Sensitivity: 0.8172769445570418\n",
      "Specificity: 0.7817230424219772\n",
      "G-Mean: 0.7993023330382992\n",
      "Confusion matrix:\n",
      "[[ 4183  1168]\n",
      " [ 4057 18146]]\n"
     ]
    }
   ],
   "source": [
    "# class_weight={1:1, 0:2}\n",
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(X_train_res, Y_train_res.astype(int))\n",
    "results(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('histo3v', 96.06255826332563)\n",
      "2 ('cslymphn', 25.57801927708296)\n",
      "3 ('csexten', 22.994834502017223)\n",
      "4 ('surgprif', 13.530888430157434)\n",
      "5 ('csmetsdx', 7.281425159591815)\n",
      "6 ('dx_conf', 7.057789032407945)\n",
      "7 ('no_surg', 1.4832789203341878)\n",
      "8 ('primsite', 1.2447061891246762)\n",
      "9 ('summ2k', 0.9112371113004079)\n",
      "10 ('reg', 0.7349946965039462)\n",
      "11 ('csrgeval', 0.6808676684096703)\n",
      "12 ('csmteval', 0.5873336906383287)\n",
      "13 ('age_dx', 0.5858548689413616)\n",
      "14 ('grade', 0.5565595791808087)\n",
      "15 ('mar_stat', 0.4956490969463544)\n",
      "16 ('cstseval', 0.43000020025116614)\n",
      "17 ('eod10_pn', 0.37645871245648516)\n",
      "18 ('beho3v', 0.3170906665926988)\n",
      "19 ('tumsiz', 0.09472825437103119)\n",
      "20 ('sex', 0.08505543770586206)\n",
      "21 ('maligcount', 0.018261461444274315)\n"
     ]
    }
   ],
   "source": [
    "feature_importance_rank(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.05737697073777099\n",
      "1 0.034081608052809305\n",
      "2 -0.05772787551449055\n",
      "3 -0.06030471897979592\n",
      "4 -0.05322176342373494\n",
      "5 0.03784303999854836\n",
      "6 0.09327584825525215\n",
      "7 0.050007374981851684\n",
      "8 -0.07919235184652058\n",
      "9 0.24544618182879085\n",
      "10 -0.04102900592776424\n",
      "11 -0.07742918766640221\n",
      "12 -0.09088765498982207\n",
      "13 -0.0591072158469683\n",
      "14 -0.06721070667018697\n",
      "15 0.020042280401000912\n",
      "16 -0.11485471259687782\n",
      "17 0.018630336788553952\n",
      "18 -0.058855853395692534\n",
      "19 0.020581389903585903\n",
      "20 0.14431866884314906\n",
      "21 -0.5497503445430474\n",
      "22 -0.012686166475178179\n",
      "23 -0.43829196280586513\n",
      "24 -0.09863556406214125\n",
      "25 -1.4046934853459874\n",
      "26 -0.9305335449850675\n",
      "27 -0.012686166475178179\n",
      "28 -0.04043259287881241\n",
      "29 0.7455695283438797\n",
      "30 -0.9615955827727058\n",
      "31 -0.39172951927389676\n",
      "32 -0.8357772471151096\n",
      "33 -0.0023464388686222095\n",
      "34 -0.32741340594896373\n",
      "35 1.8529960748133631\n",
      "36 0.5979626383218951\n",
      "37 0.12380717943897646\n",
      "38 0.001636163882496957\n",
      "39 0.28870767350396637\n",
      "40 2.1099413505184628\n",
      "41 -0.4117614861202147\n",
      "42 0.08446950392932516\n",
      "43 -0.34087009925827444\n",
      "44 -0.012686166475178179\n",
      "45 0.07132092869073078\n",
      "46 -0.3150309861665461\n",
      "47 -0.1504752883569661\n",
      "48 0.16289566293500696\n",
      "49 -0.16405772963143664\n",
      "50 0.9923404692470302\n",
      "51 -0.012686166475178179\n",
      "52 -0.6112840955371238\n",
      "53 -0.035839210256749646\n",
      "54 0.17667226493799298\n",
      "55 -0.2846016217019059\n",
      "56 -0.35269067489856537\n",
      "57 0.03539951646607497\n",
      "58 -0.42980514146225185\n",
      "59 0.41738169373172573\n",
      "60 -0.2999851091443184\n",
      "61 -1.2440825261612907\n",
      "62 0.002179272269839866\n",
      "63 -0.7785532198244175\n",
      "64 0.019911627281530002\n",
      "65 -0.33415215337783977\n",
      "66 0.13476523321645392\n",
      "67 0.3437507196867573\n",
      "68 -0.4760026063528167\n",
      "69 -0.4910726252337272\n",
      "70 -0.6908857100332968\n",
      "71 1.0283118207284778\n",
      "72 -0.0005199008570231217\n",
      "73 0.020548724385880686\n",
      "74 0.9708234605456145\n",
      "75 0.034321451758026394\n",
      "76 -0.6348269456395524\n",
      "77 -0.8168688122868528\n",
      "78 0.008459922620021034\n",
      "79 -0.5934020912134349\n",
      "80 0.02484587261472096\n",
      "81 -0.09838705702272169\n",
      "82 0.8610047465467753\n",
      "83 1.6124822037176623\n",
      "84 0.5880822072589293\n",
      "85 0.2131082237772903\n",
      "86 0.04172345382653952\n",
      "87 1.2696219454993165\n",
      "88 -0.18093364261322364\n",
      "89 0.8340592366795428\n",
      "90 -0.7438431466999548\n",
      "91 0.6970567081631824\n",
      "92 0.10177889738247829\n",
      "93 0.03875485243324366\n",
      "94 -1.2146174727581063\n",
      "95 0.0402146707624216\n",
      "96 0.15787573724223336\n",
      "97 0.010003836039706513\n",
      "98 0.04755958186921837\n",
      "99 -0.23732891505263107\n",
      "100 0.17292840834586623\n",
      "101 0.07657169866078889\n",
      "102 -0.1428647892628937\n",
      "103 -0.1903340061571308\n",
      "104 0.045640189002495786\n",
      "105 -0.36580253132761165\n",
      "106 -0.23047478410793232\n",
      "107 -0.4481751610599391\n",
      "108 2.3714656306113038\n",
      "109 -0.410769642775418\n",
      "110 -0.0698929207869941\n",
      "111 -0.08721565112637011\n",
      "112 -0.8352519382727346\n",
      "113 0.03627111511718521\n",
      "114 0.14308821173451686\n",
      "115 0.44040977003409065\n",
      "116 0.5977329031083224\n",
      "117 0.5569134542022844\n",
      "118 0.16742596627971257\n",
      "119 0.022823572818594564\n",
      "120 -0.012686166475178179\n",
      "121 0.3941273770301414\n",
      "122 0.09952004564921478\n",
      "123 1.3907044660609802\n",
      "124 0.7368513083282134\n",
      "125 0.4832824359715561\n",
      "126 0.33746037081372154\n",
      "127 0.5057037612323629\n",
      "128 0.030231338553978613\n",
      "129 -0.005909174098632677\n",
      "130 -0.13301201592788087\n",
      "131 0.04651244260308328\n",
      "132 0.004151706624656926\n",
      "133 0.08470157083737084\n",
      "134 -0.8245028484613376\n",
      "135 -0.7210329106825729\n",
      "136 -0.1170076407770084\n",
      "137 -0.012033982736688613\n",
      "138 -1.1686421644882865\n",
      "139 0.1751026240612998\n",
      "140 -0.08976818689859975\n",
      "141 0.06503874826289782\n",
      "142 0.06427631160024941\n",
      "143 0.18837163346119704\n",
      "144 -0.2666037989254439\n",
      "145 0.09914484508522431\n",
      "146 0.11170004112117835\n",
      "147 0.20848409025542994\n",
      "148 -0.48770013589597505\n",
      "149 -0.3579310689352956\n",
      "150 -0.24386008566716594\n",
      "151 -0.5330718949960926\n",
      "152 -0.2068485188153216\n",
      "153 -0.3033639852072151\n",
      "154 -0.27833517964729404\n",
      "155 -0.34873057905369526\n",
      "156 -0.34776478341015227\n",
      "157 -0.4708240208547373\n",
      "158 -0.4915738105967645\n",
      "159 0.2788087551431866\n",
      "160 -0.39554363690725863\n",
      "161 -0.2000902666291639\n",
      "162 0.24303457450061228\n",
      "163 -0.31042595372810505\n",
      "164 -0.3511544253666842\n",
      "165 0.1756741858750553\n",
      "166 -0.175619910626607\n",
      "167 0.14869480925285117\n",
      "168 0.38945782141352714\n",
      "169 -0.06940226725100708\n",
      "170 0.1846460897920216\n",
      "171 -0.0217136102724968\n",
      "172 0.06755007519043219\n",
      "173 0.034923953702358713\n",
      "174 0.003218045609183798\n",
      "175 0.1274121133462887\n",
      "176 0.004283142294354242\n",
      "177 0.4399287026535692\n",
      "178 0.3483356709513902\n",
      "179 -0.4543858580604706\n",
      "180 -0.6651007814819445\n",
      "181 0.18629939500285034\n",
      "182 -0.31352907854533196\n",
      "183 -0.5445430796362207\n",
      "184 0.2652276852025237\n",
      "185 0.04627530294696977\n",
      "186 0.10087973420362611\n",
      "187 0.3665353072580656\n",
      "188 0.12439652508883105\n",
      "189 0.16492154249301316\n",
      "190 0.15079972382907703\n",
      "191 0.14507064387554877\n",
      "192 0.306367962122682\n",
      "193 0.09622180925728106\n",
      "194 0.20912588046699607\n",
      "195 0.5462654899230934\n",
      "196 -0.1238147216663808\n",
      "197 -0.1521893120232483\n",
      "198 -0.41451368114744747\n",
      "199 0.3628044838454373\n",
      "200 0.47205000351128484\n",
      "201 -0.8358153270050006\n",
      "202 -0.23261179274728128\n",
      "203 -0.19635062832382305\n",
      "204 -0.2333409201985948\n",
      "205 -0.4314378031665205\n",
      "206 0.14950511592639962\n",
      "207 -0.20111447545394748\n",
      "208 -0.967164447775551\n",
      "209 -0.04384858236530579\n",
      "210 0.2805859225342679\n",
      "211 0.16576945287152128\n",
      "212 0.08263844438490521\n",
      "213 -0.001054399889821998\n",
      "214 -0.3689908899646512\n",
      "215 0.09341973580393734\n",
      "216 0.19076970532362963\n",
      "217 -0.06895178367425109\n",
      "218 0.008738355668357841\n",
      "219 -0.1517759185225187\n",
      "220 0.01792196797349401\n",
      "221 -0.203004078936523\n",
      "222 0.009267928229685808\n",
      "223 0.20435471721476123\n",
      "224 0.09083020729467002\n",
      "225 -0.031025655610451716\n",
      "226 -0.11452629391800843\n",
      "227 -0.15127773903006209\n",
      "228 0.20746862091038987\n",
      "229 -0.12031511062238047\n",
      "230 0.007333705585795164\n",
      "231 0.25263115394079644\n",
      "232 -0.14474516921367467\n",
      "233 -0.21966912626216745\n",
      "234 -0.5933163089771571\n",
      "235 0.40992756356136273\n",
      "236 -0.012686166475178179\n",
      "237 0.38568102952782757\n",
      "238 -0.11332497407878007\n",
      "239 0.5673352168499558\n",
      "240 0.05638751087662103\n",
      "241 0.17633738081683845\n",
      "242 0.10813635275137573\n",
      "243 0.18926415230916588\n",
      "244 0.10159278134719998\n",
      "245 -0.1683298150640193\n",
      "246 0.04788219704986023\n",
      "247 0.5670260606463017\n",
      "248 -0.020405721868965165\n",
      "249 0.05033239530414316\n",
      "250 -0.08943756275705655\n",
      "251 -0.05795177828142933\n",
      "252 -0.04504402464357842\n",
      "253 -0.20596873593670545\n",
      "254 -0.04901320184613879\n",
      "255 -0.3270843089818798\n",
      "256 0.12425045092636607\n",
      "257 -0.32085311225400176\n",
      "258 -0.2615536404035745\n",
      "259 0.14155255368978945\n",
      "260 -0.36486180048216865\n",
      "261 -0.16684526335635458\n",
      "262 -0.05340864534013873\n",
      "263 -0.09212560974939368\n",
      "264 -0.2861997971967888\n",
      "265 0.1291027875938726\n",
      "266 0.07788017219272181\n",
      "267 -0.22285281183414468\n",
      "268 -0.3226054364354061\n",
      "269 1.5987993136999672\n",
      "270 -0.19595286641984802\n",
      "271 -0.21288247863766052\n",
      "272 -0.0973367381769227\n",
      "273 -0.7011661532330073\n",
      "274 0.23732891505263107\n",
      "275 0.1178950938063644\n",
      "276 -0.05631319876100399\n",
      "277 -0.3026174283863307\n",
      "278 -0.03435188112126889\n",
      "279 -0.05981164771391931\n",
      "280 0.18039263172638173\n",
      "281 -0.022881471596975272\n",
      "282 -0.08305779848162007\n",
      "283 -0.004791507214376213\n",
      "284 -0.14016597015342516\n",
      "285 -0.012082921604170812\n",
      "286 -0.03853509002263222\n",
      "287 0.033709731834094814\n",
      "288 0.47022745559792734\n",
      "289 0.048312100215555834\n",
      "290 -0.06842431799234139\n",
      "291 -0.30110226431620835\n",
      "292 -0.087603891036009\n",
      "293 -0.10811436909739164\n",
      "294 -0.051043309387862286\n",
      "295 0.049837956287448006\n",
      "296 -0.007843980638114366\n",
      "297 -0.4568178048976939\n",
      "298 -0.2653654249130972\n",
      "299 0.03844596388376672\n",
      "300 -0.051250025611890716\n"
     ]
    }
   ],
   "source": [
    "for key, val in enumerate(lr.coef_[0]):\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(108, 2.3714656306113038),\n",
       " (40, 2.1099413505184628),\n",
       " (35, 1.8529960748133631),\n",
       " (83, 1.6124822037176623),\n",
       " (269, 1.5987993136999672),\n",
       " (123, 1.3907044660609802),\n",
       " (87, 1.2696219454993165),\n",
       " (71, 1.0283118207284778),\n",
       " (50, 0.9923404692470302),\n",
       " (74, 0.9708234605456145),\n",
       " (82, 0.8610047465467753),\n",
       " (89, 0.8340592366795428),\n",
       " (29, 0.7455695283438797),\n",
       " (124, 0.7368513083282134),\n",
       " (91, 0.6970567081631824),\n",
       " (36, 0.5979626383218951),\n",
       " (116, 0.5977329031083224),\n",
       " (84, 0.5880822072589293),\n",
       " (239, 0.5673352168499558),\n",
       " (247, 0.5670260606463017),\n",
       " (117, 0.5569134542022844),\n",
       " (195, 0.5462654899230934),\n",
       " (127, 0.5057037612323629),\n",
       " (125, 0.4832824359715561),\n",
       " (200, 0.47205000351128484),\n",
       " (288, 0.47022745559792734),\n",
       " (115, 0.44040977003409065),\n",
       " (177, 0.4399287026535692),\n",
       " (59, 0.41738169373172573),\n",
       " (235, 0.40992756356136273),\n",
       " (121, 0.3941273770301414),\n",
       " (168, 0.38945782141352714),\n",
       " (237, 0.38568102952782757),\n",
       " (187, 0.3665353072580656),\n",
       " (199, 0.3628044838454373),\n",
       " (178, 0.3483356709513902),\n",
       " (67, 0.3437507196867573),\n",
       " (126, 0.33746037081372154),\n",
       " (192, 0.306367962122682),\n",
       " (39, 0.28870767350396637),\n",
       " (210, 0.2805859225342679),\n",
       " (159, 0.2788087551431866),\n",
       " (184, 0.2652276852025237),\n",
       " (231, 0.25263115394079644),\n",
       " (9, 0.24544618182879085),\n",
       " (162, 0.24303457450061228),\n",
       " (274, 0.23732891505263107),\n",
       " (85, 0.2131082237772903),\n",
       " (194, 0.20912588046699607),\n",
       " (147, 0.20848409025542994),\n",
       " (228, 0.20746862091038987),\n",
       " (223, 0.20435471721476123),\n",
       " (216, 0.19076970532362963),\n",
       " (243, 0.18926415230916588),\n",
       " (143, 0.18837163346119704),\n",
       " (181, 0.18629939500285034),\n",
       " (170, 0.1846460897920216),\n",
       " (280, 0.18039263172638173),\n",
       " (54, 0.17667226493799298),\n",
       " (241, 0.17633738081683845),\n",
       " (165, 0.1756741858750553),\n",
       " (139, 0.1751026240612998),\n",
       " (100, 0.17292840834586623),\n",
       " (118, 0.16742596627971257),\n",
       " (211, 0.16576945287152128),\n",
       " (189, 0.16492154249301316),\n",
       " (48, 0.16289566293500696),\n",
       " (96, 0.15787573724223336),\n",
       " (190, 0.15079972382907703),\n",
       " (206, 0.14950511592639962),\n",
       " (167, 0.14869480925285117),\n",
       " (191, 0.14507064387554877),\n",
       " (20, 0.14431866884314906),\n",
       " (114, 0.14308821173451686),\n",
       " (259, 0.14155255368978945),\n",
       " (66, 0.13476523321645392),\n",
       " (265, 0.1291027875938726),\n",
       " (175, 0.1274121133462887),\n",
       " (188, 0.12439652508883105),\n",
       " (256, 0.12425045092636607),\n",
       " (37, 0.12380717943897646),\n",
       " (275, 0.1178950938063644),\n",
       " (146, 0.11170004112117835),\n",
       " (242, 0.10813635275137573),\n",
       " (92, 0.10177889738247829),\n",
       " (244, 0.10159278134719998),\n",
       " (186, 0.10087973420362611),\n",
       " (122, 0.09952004564921478),\n",
       " (145, 0.09914484508522431),\n",
       " (193, 0.09622180925728106),\n",
       " (215, 0.09341973580393734),\n",
       " (6, 0.09327584825525215),\n",
       " (224, 0.09083020729467002),\n",
       " (133, 0.08470157083737084),\n",
       " (42, 0.08446950392932516),\n",
       " (212, 0.08263844438490521),\n",
       " (266, 0.07788017219272181),\n",
       " (101, 0.07657169866078889),\n",
       " (45, 0.07132092869073078),\n",
       " (172, 0.06755007519043219),\n",
       " (141, 0.06503874826289782),\n",
       " (142, 0.06427631160024941),\n",
       " (240, 0.05638751087662103),\n",
       " (249, 0.05033239530414316),\n",
       " (7, 0.050007374981851684),\n",
       " (295, 0.049837956287448006),\n",
       " (289, 0.048312100215555834),\n",
       " (246, 0.04788219704986023),\n",
       " (98, 0.04755958186921837),\n",
       " (131, 0.04651244260308328),\n",
       " (185, 0.04627530294696977),\n",
       " (104, 0.045640189002495786),\n",
       " (86, 0.04172345382653952),\n",
       " (95, 0.0402146707624216),\n",
       " (93, 0.03875485243324366),\n",
       " (299, 0.03844596388376672),\n",
       " (5, 0.03784303999854836),\n",
       " (113, 0.03627111511718521),\n",
       " (57, 0.03539951646607497),\n",
       " (173, 0.034923953702358713),\n",
       " (75, 0.034321451758026394),\n",
       " (1, 0.034081608052809305),\n",
       " (287, 0.033709731834094814),\n",
       " (128, 0.030231338553978613),\n",
       " (80, 0.02484587261472096),\n",
       " (119, 0.022823572818594564),\n",
       " (19, 0.020581389903585903),\n",
       " (73, 0.020548724385880686),\n",
       " (15, 0.020042280401000912),\n",
       " (64, 0.019911627281530002),\n",
       " (17, 0.018630336788553952),\n",
       " (220, 0.01792196797349401),\n",
       " (97, 0.010003836039706513),\n",
       " (222, 0.009267928229685808),\n",
       " (218, 0.008738355668357841),\n",
       " (78, 0.008459922620021034),\n",
       " (230, 0.007333705585795164),\n",
       " (176, 0.004283142294354242),\n",
       " (132, 0.004151706624656926),\n",
       " (174, 0.003218045609183798),\n",
       " (62, 0.002179272269839866),\n",
       " (38, 0.001636163882496957),\n",
       " (72, -0.0005199008570231217),\n",
       " (213, -0.001054399889821998),\n",
       " (33, -0.0023464388686222095),\n",
       " (283, -0.004791507214376213),\n",
       " (129, -0.005909174098632677),\n",
       " (296, -0.007843980638114366),\n",
       " (137, -0.012033982736688613),\n",
       " (285, -0.012082921604170812),\n",
       " (22, -0.012686166475178179),\n",
       " (27, -0.012686166475178179),\n",
       " (44, -0.012686166475178179),\n",
       " (51, -0.012686166475178179),\n",
       " (120, -0.012686166475178179),\n",
       " (236, -0.012686166475178179),\n",
       " (248, -0.020405721868965165),\n",
       " (171, -0.0217136102724968),\n",
       " (281, -0.022881471596975272),\n",
       " (225, -0.031025655610451716),\n",
       " (278, -0.03435188112126889),\n",
       " (53, -0.035839210256749646),\n",
       " (286, -0.03853509002263222),\n",
       " (28, -0.04043259287881241),\n",
       " (10, -0.04102900592776424),\n",
       " (209, -0.04384858236530579),\n",
       " (252, -0.04504402464357842),\n",
       " (254, -0.04901320184613879),\n",
       " (294, -0.051043309387862286),\n",
       " (300, -0.051250025611890716),\n",
       " (4, -0.05322176342373494),\n",
       " (262, -0.05340864534013873),\n",
       " (276, -0.05631319876100399),\n",
       " (0, -0.05737697073777099),\n",
       " (2, -0.05772787551449055),\n",
       " (251, -0.05795177828142933),\n",
       " (18, -0.058855853395692534),\n",
       " (13, -0.0591072158469683),\n",
       " (279, -0.05981164771391931),\n",
       " (3, -0.06030471897979592),\n",
       " (14, -0.06721070667018697),\n",
       " (290, -0.06842431799234139),\n",
       " (217, -0.06895178367425109),\n",
       " (169, -0.06940226725100708),\n",
       " (110, -0.0698929207869941),\n",
       " (11, -0.07742918766640221),\n",
       " (8, -0.07919235184652058),\n",
       " (282, -0.08305779848162007),\n",
       " (111, -0.08721565112637011),\n",
       " (292, -0.087603891036009),\n",
       " (250, -0.08943756275705655),\n",
       " (140, -0.08976818689859975),\n",
       " (12, -0.09088765498982207),\n",
       " (263, -0.09212560974939368),\n",
       " (272, -0.0973367381769227),\n",
       " (81, -0.09838705702272169),\n",
       " (24, -0.09863556406214125),\n",
       " (293, -0.10811436909739164),\n",
       " (238, -0.11332497407878007),\n",
       " (226, -0.11452629391800843),\n",
       " (16, -0.11485471259687782),\n",
       " (136, -0.1170076407770084),\n",
       " (229, -0.12031511062238047),\n",
       " (196, -0.1238147216663808),\n",
       " (130, -0.13301201592788087),\n",
       " (284, -0.14016597015342516),\n",
       " (102, -0.1428647892628937),\n",
       " (232, -0.14474516921367467),\n",
       " (47, -0.1504752883569661),\n",
       " (227, -0.15127773903006209),\n",
       " (219, -0.1517759185225187),\n",
       " (197, -0.1521893120232483),\n",
       " (49, -0.16405772963143664),\n",
       " (261, -0.16684526335635458),\n",
       " (245, -0.1683298150640193),\n",
       " (166, -0.175619910626607),\n",
       " (88, -0.18093364261322364),\n",
       " (103, -0.1903340061571308),\n",
       " (270, -0.19595286641984802),\n",
       " (203, -0.19635062832382305),\n",
       " (161, -0.2000902666291639),\n",
       " (207, -0.20111447545394748),\n",
       " (221, -0.203004078936523),\n",
       " (253, -0.20596873593670545),\n",
       " (152, -0.2068485188153216),\n",
       " (271, -0.21288247863766052),\n",
       " (233, -0.21966912626216745),\n",
       " (267, -0.22285281183414468),\n",
       " (106, -0.23047478410793232),\n",
       " (202, -0.23261179274728128),\n",
       " (204, -0.2333409201985948),\n",
       " (99, -0.23732891505263107),\n",
       " (150, -0.24386008566716594),\n",
       " (258, -0.2615536404035745),\n",
       " (298, -0.2653654249130972),\n",
       " (144, -0.2666037989254439),\n",
       " (154, -0.27833517964729404),\n",
       " (55, -0.2846016217019059),\n",
       " (264, -0.2861997971967888),\n",
       " (60, -0.2999851091443184),\n",
       " (291, -0.30110226431620835),\n",
       " (277, -0.3026174283863307),\n",
       " (153, -0.3033639852072151),\n",
       " (163, -0.31042595372810505),\n",
       " (182, -0.31352907854533196),\n",
       " (46, -0.3150309861665461),\n",
       " (257, -0.32085311225400176),\n",
       " (268, -0.3226054364354061),\n",
       " (255, -0.3270843089818798),\n",
       " (34, -0.32741340594896373),\n",
       " (65, -0.33415215337783977),\n",
       " (43, -0.34087009925827444),\n",
       " (156, -0.34776478341015227),\n",
       " (155, -0.34873057905369526),\n",
       " (164, -0.3511544253666842),\n",
       " (56, -0.35269067489856537),\n",
       " (149, -0.3579310689352956),\n",
       " (260, -0.36486180048216865),\n",
       " (105, -0.36580253132761165),\n",
       " (214, -0.3689908899646512),\n",
       " (31, -0.39172951927389676),\n",
       " (160, -0.39554363690725863),\n",
       " (109, -0.410769642775418),\n",
       " (41, -0.4117614861202147),\n",
       " (198, -0.41451368114744747),\n",
       " (58, -0.42980514146225185),\n",
       " (205, -0.4314378031665205),\n",
       " (23, -0.43829196280586513),\n",
       " (107, -0.4481751610599391),\n",
       " (179, -0.4543858580604706),\n",
       " (297, -0.4568178048976939),\n",
       " (157, -0.4708240208547373),\n",
       " (68, -0.4760026063528167),\n",
       " (148, -0.48770013589597505),\n",
       " (69, -0.4910726252337272),\n",
       " (158, -0.4915738105967645),\n",
       " (151, -0.5330718949960926),\n",
       " (183, -0.5445430796362207),\n",
       " (21, -0.5497503445430474),\n",
       " (234, -0.5933163089771571),\n",
       " (79, -0.5934020912134349),\n",
       " (52, -0.6112840955371238),\n",
       " (76, -0.6348269456395524),\n",
       " (180, -0.6651007814819445),\n",
       " (70, -0.6908857100332968),\n",
       " (273, -0.7011661532330073),\n",
       " (135, -0.7210329106825729),\n",
       " (90, -0.7438431466999548),\n",
       " (63, -0.7785532198244175),\n",
       " (77, -0.8168688122868528),\n",
       " (134, -0.8245028484613376),\n",
       " (112, -0.8352519382727346),\n",
       " (32, -0.8357772471151096),\n",
       " (201, -0.8358153270050006),\n",
       " (26, -0.9305335449850675),\n",
       " (30, -0.9615955827727058),\n",
       " (208, -0.967164447775551),\n",
       " (138, -1.1686421644882865),\n",
       " (94, -1.2146174727581063),\n",
       " (61, -1.2440825261612907),\n",
       " (25, -1.4046934853459874)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(lr.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scoring=make_scorer(roc_auc_score)\n",
    "param_grid = [{'max_features':[175,200], 'n_estimators':[10,15,20], 'min_samples_leaf':[150,175,200]}]\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "            param_grid, cv=3, scoring=make_scorer(roc_auc_score), \n",
    "            verbose=5\n",
    ")\n",
    "rf_grid_search.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rf_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(rf_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8535602816288016\n",
      "ROC: 0.8721976873104935\n",
      "PPV: 0.8884707492302429\n",
      "NPV: 0.6577937649880096\n",
      "Sensitivity: 0.9357294059361347\n",
      "Specificity: 0.5126144645860586\n",
      "G-Mean: 0.692580990514021\n",
      "Confusion matrix:\n",
      "[[ 2743  2608]\n",
      " [ 1427 20776]]\n"
     ]
    }
   ],
   "source": [
    "# class_weight={1:1,0:3}\n",
    "rf_clf = RandomForestClassifier(n_estimators=20, min_samples_leaf=150, max_features=200, random_state=42)\n",
    "rf_clf.fit(X_train, Y_train)\n",
    "results(rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('csmetsdx', 0.3889737599586425)\n",
      "2 ('summ2k', 0.2119298921160748)\n",
      "3 ('age_dx', 0.08708194288580808)\n",
      "4 ('no_surg', 0.08474243849871409)\n",
      "5 ('eod10_pn', 0.0742133772951314)\n",
      "6 ('surgprif', 0.0528253895311063)\n",
      "7 ('tumsiz', 0.03281095280458478)\n",
      "8 ('grade', 0.017621186775247075)\n",
      "9 ('primsite', 0.0074967519415122755)\n",
      "10 ('csexten', 0.007282790887804617)\n",
      "11 ('mar_stat', 0.00681587596495206)\n",
      "12 ('histo3v', 0.0055414588290072075)\n",
      "13 ('dx_conf', 0.005274295242352326)\n",
      "14 ('cslymphn', 0.005241316965868953)\n",
      "15 ('maligcount', 0.004177950923072821)\n",
      "16 ('sex', 0.0021267599879958013)\n",
      "17 ('reg', 0.0016841953973572982)\n",
      "18 ('csmteval', 0.0015940421256534537)\n",
      "19 ('beho3v', 0.0012904150078187596)\n",
      "20 ('cstseval', 0.0011654497314790646)\n",
      "21 ('csrgeval', 0.0010737627260390672)\n"
     ]
    }
   ],
   "source": [
    "feature_importance_rank(rf_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(rf_clf.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(rf_grid_search, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_clf = LinearSVC(C=.01)\n",
    "svm_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8521014307613695\n",
      "ROC: 0.7031383223351095\n",
      "PPV: 0.8799617055747846\n",
      "NPV: 0.6699566682715455\n",
      "Sensitivity: 0.9457437967470023\n",
      "Specificity: 0.46053284792321697\n",
      "G-Mean: 0.6599591533736107\n",
      "Confusion matrix:\n",
      "[[ 2783  3260]\n",
      " [ 1371 23898]]\n"
     ]
    }
   ],
   "source": [
    "results(svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('histo3v', 9.196570515231087)\n",
      "2 ('cslymphn', 4.173764301426509)\n",
      "3 ('csexten', 3.431019655582666)\n",
      "4 ('csmetsdx', 1.7683391128567432)\n",
      "5 ('surgprif', 1.023685329861967)\n",
      "6 ('primsite', 0.49641579672149716)\n",
      "7 ('no_surg', 0.45462887016807974)\n",
      "8 ('csmteval', 0.383803137445053)\n",
      "9 ('reg', 0.3450647045112549)\n",
      "10 ('dx_conf', 0.3355456127906983)\n",
      "11 ('summ2k', 0.2197410222547135)\n",
      "12 ('grade', 0.16209525477515435)\n",
      "13 ('age_dx', 0.1380847916237922)\n",
      "14 ('mar_stat', 0.1191835444475507)\n",
      "15 ('cstseval', 0.10887718026656777)\n",
      "16 ('csrgeval', 0.10383574812886044)\n",
      "17 ('beho3v', 0.09099250071731302)\n",
      "18 ('eod10_pn', 0.08383812366116374)\n",
      "19 ('sex', 0.03243497295414094)\n",
      "20 ('maligcount', 0.01958078722576911)\n",
      "21 ('tumsiz', 0.01718338686161156)\n"
     ]
    }
   ],
   "source": [
    "feature_importance_rank(svm_clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(svm_clf.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=225, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=300, min_samples_split=2,\n",
       "            min_wei...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "clf1 = RandomForestClassifier(n_estimators=20, min_samples_leaf=300, max_features=225)\n",
    "clf2 = LogisticRegression(C=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=20, \n",
    "                           algorithm=\"SAMME.R\", learning_rate=1)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[\n",
    "    ('rf', clf1), ('lr', clf2), ('ab', clf4)\n",
    "], voting='soft')\n",
    "eclf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8581314878892734\n",
      "ROC: 0.8677830987418913\n",
      "PPV: 0.8870723584620043\n",
      "NPV: 0.6475770925110133\n",
      "Sensitivity: 0.948220064724919\n",
      "Specificity: 0.4407796101949025\n",
      "G-Mean: 0.6464952207931897\n",
      "Confusion matrix:\n",
      "[[ 294  373]\n",
      " [ 160 2930]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "results(eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, max_samples=3000,\n",
    "                           bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(bag_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "bbc = BalancedBaggingClassifier(DecisionTreeClassifier(), n_estimators=200, max_samples=3000,\n",
    "                           bootstrap=True, n_jobs=-1)\n",
    "bbc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(bbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scoring=make_scorer(roc_auc_score)\n",
    "param_grid = [{\"n_estimators\":[100, 115, 130, 145], \"learning_rate\":[.6, .7, .8, .9, 1]}]\n",
    "ab_grid_search = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME.R\"), \n",
    "            param_grid, cv=3, scoring=make_scorer(roc_auc_score), \n",
    "            verbose=5\n",
    ")\n",
    "ab_grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = ab_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(ab_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(ab_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), n_estimators=200, \n",
    "                           algorithm=\"SAMME.R\", learning_rate=1)\n",
    "ab_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8365717327655043\n",
      "ROC: 0.815020789770952\n",
      "PPV: 0.8841843088418431\n",
      "NPV: 0.5559633027522936\n",
      "Sensitivity: 0.9214795587280986\n",
      "Specificity: 0.4488888888888889\n",
      "G-Mean: 0.6431500099131461\n",
      "Confusion matrix:\n",
      "[[ 303  372]\n",
      " [ 242 2840]]\n"
     ]
    }
   ],
   "source": [
    "results(ab_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('csexten', 0.18)\n",
      "2 ('age_dx', 0.125)\n",
      "3 ('eod10_pn', 0.1)\n",
      "4 ('histo3v', 0.1)\n",
      "5 ('csmetsdx', 0.085)\n",
      "6 ('tumsiz', 0.08)\n",
      "7 ('surgprif', 0.065)\n",
      "8 ('primsite', 0.04)\n",
      "9 ('summ2k', 0.039999999999999994)\n",
      "10 ('reg', 0.035)\n",
      "11 ('grade', 0.030000000000000002)\n",
      "12 ('mar_stat', 0.02)\n",
      "13 ('dx_conf', 0.02)\n",
      "14 ('no_surg', 0.02)\n",
      "15 ('cslymphn', 0.015)\n",
      "16 ('cstseval', 0.015)\n",
      "17 ('csrgeval', 0.015)\n",
      "18 ('beho3v', 0.01)\n",
      "19 ('sex', 0.005)\n",
      "20 ('csmteval', 0.005)\n",
      "21 ('maligcount', 0.0)\n"
     ]
    }
   ],
   "source": [
    "feature_importance_rank(ab_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=400)\n",
    "gb_clf.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(gb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(ratio={0: 20000, 1:27731},random_state=42)\n",
    "X_train_res, Y_train_res = sm.fit_sample(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "us = RandomUnderSampler(ratio={0:Counter(Y_train)[0], 1:Counter(Y_train)[0]})\n",
    "X_train_res, Y_train_res = us.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 47992, 1: 47992})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "os = RandomOverSampler(ratio={0:20000, 1:27731})\n",
    "X_train_res, Y_train_res = os.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
