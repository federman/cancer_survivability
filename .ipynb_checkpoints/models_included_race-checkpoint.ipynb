{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_h = np.load('../Data_Standardized/hispanic/X.npy')\n",
    "Y_h = np.load('../Data_Standardized/hispanic/Y2.npy')\n",
    "X_w = np.load('../Data_Standardized/white/X.npy')\n",
    "Y_w = np.load('../Data_Standardized/white/Y2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_h = np.hstack((X_h, np.ones((len(Y_h),1))))\n",
    "X_w = np.hstack((X_w, -1*np.ones((len(Y_w),1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((X_h, X_w))\n",
    "Y = np.concatenate((Y_h, Y_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(X, Y):\n",
    "    # shuffle\n",
    "    np.random.seed(97)\n",
    "    idx = np.random.permutation(len(X))\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "    \n",
    "    #X = X[:size_hispanic]\n",
    "    #Y = Y[:size_hispanic]\n",
    "\n",
    "    # split into training and test sets\n",
    "    TEST_SET_SIZE = int(0.1*len(Y))\n",
    "    X_train, X_test = X[:-TEST_SET_SIZE], X[-TEST_SET_SIZE:]\n",
    "    Y_train, Y_test = Y[:-TEST_SET_SIZE].astype(int), Y[-TEST_SET_SIZE:].astype(int)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = split_train_test(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "Fit scaler based on training data, then transform both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# feature scaling: scale features based on training data only\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def feature_scale(X_train, X_test):\n",
    "    \n",
    "    mm_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    X_train[:,-5:] = mm_scaler.fit_transform(X_train[:,-5:])\n",
    "    X_test[:,-5:] = mm_scaler.transform(X_test[:,-5:])\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train[:,-5:-1] = std_scaler.fit_transform(X_train[:,-5:-1])\n",
    "    X_test[:,-5:-1] = std_scaler.transform(X_test[:,-5:-1])\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "X_train, X_test = feature_scale(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def results(classifier):\n",
    "    Y_pred_test = classifier.predict(X_test)\n",
    "    print(\"Test accuracy score: \" + str(accuracy_score(Y_test.astype(int), Y_pred_test)))\n",
    "    #print(\"ROC: \" + str(roc_auc_score(Y_test, classifier.predict_proba(X_test)[:,1])))\n",
    "    print(\"ROC: \" + str(roc_auc_score(Y_test, Y_pred_test)))\n",
    "    matrix = confusion_matrix(Y_test.astype(int), Y_pred_test)\n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    ppv = tp/(tp+fp)\n",
    "    npv = tn/(tn+fn)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    g_mean = np.sqrt(sensitivity*specificity)\n",
    "    print(\"PPV: \" + str(ppv))\n",
    "    print(\"NPV: \" + str(npv))\n",
    "    print(\"Sensitivity: \" + str(sensitivity))\n",
    "    print(\"Specificity: \" + str(specificity))\n",
    "    print(\"G-Mean: \" + str(g_mean))\n",
    "    print(\"Confusion matrix:\\n\" + str(matrix))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('white_codes.pkl', 'rb') as f_w:\n",
    "    white_codes = pickle.load(f_w)\n",
    "with open('hispanic_codes.pkl', 'rb') as f_h:\n",
    "    hispanic_codes = pickle.load(f_h)\n",
    "with open('mixed_codes.pkl', 'rb') as f_m:\n",
    "    mixed_codes = pickle.load(f_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281810, 375)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'mar_stat', 0): array(['1', '2', '3', '4', '5', '6', '9'], dtype='<U1'),\n",
       " (1, 'sex', 7): array(['1', '2'], dtype='<U1'),\n",
       " (2,\n",
       "  'primsite',\n",
       "  8): array(['C180', 'C181', 'C182', 'C183', 'C184', 'C185', 'C186', 'C187',\n",
       "        'C188', 'C189', 'C199', 'C209', 'C260'], dtype='<U4'),\n",
       " (3,\n",
       "  'histo3v',\n",
       "  21): array(['8000', '8001', '8002', '8003', '8004', '8010', '8011', '8012',\n",
       "        '8013', '8015', '8020', '8021', '8022', '8030', '8031', '8032',\n",
       "        '8033', '8041', '8045', '8046', '8050', '8051', '8052', '8070',\n",
       "        '8071', '8072', '8073', '8076', '8077', '8081', '8082', '8083',\n",
       "        '8094', '8123', '8124', '8130', '8140', '8141', '8142', '8143',\n",
       "        '8144', '8145', '8147', '8160', '8201', '8210', '8211', '8213',\n",
       "        '8220', '8221', '8230', '8240', '8241', '8243', '8244', '8245',\n",
       "        '8246', '8249', '8255', '8260', '8261', '8262', '8263', '8310',\n",
       "        '8320', '8323', '8341', '8380', '8430', '8440', '8441', '8460',\n",
       "        '8461', '8470', '8471', '8472', '8480', '8481', '8490', '8500',\n",
       "        '8503', '8507', '8510', '8542', '8550', '8551', '8560', '8570',\n",
       "        '8571', '8572', '8573', '8574', '8576', '8711', '8720', '8721',\n",
       "        '8722', '8730', '8744', '8746', '8761', '8770', '8772', '8780',\n",
       "        '8800', '8801', '8802', '8804', '8805', '8806', '8815', '8830',\n",
       "        '8851', '8858', '8890', '8891', '8896', '8900', '8930', '8933',\n",
       "        '8935', '8936', '8940', '8950', '8963', '8980', '9015', '9044',\n",
       "        '9065', '9085', '9100', '9120', '9130', '9260', '9500', '9540',\n",
       "        '9560', '9561', '9580'], dtype='<U4'),\n",
       " (4, 'beho3v', 160): array(['2', '3'], dtype='<U1'),\n",
       " (5, 'grade', 161): array(['1', '2', '3', '4', '9'], dtype='<U1'),\n",
       " (6,\n",
       "  'dx_conf',\n",
       "  166): array(['1', '2', '4', '5', '6', '7', '8', '9'], dtype='<U1'),\n",
       " (7,\n",
       "  'csexten',\n",
       "  174): array(['0', '100', '110', '120', '130', '140', '150', '155', '160', '165',\n",
       "        '170', '180', '190', '200', '210', '250', '270', '300', '320',\n",
       "        '330', '335', '370', '400', '401', '410', '415', '440', '450',\n",
       "        '451', '455', '458', '460', '470', '490', '50', '500', '501',\n",
       "        '510', '511', '512', '513', '514', '550', '555', '560', '565',\n",
       "        '570', '600', '601', '610', '650', '655', '660', '665', '675',\n",
       "        '700', '701', '750', '751', '800', '810', '850', '900', '950',\n",
       "        '999'], dtype='<U3'),\n",
       " (8,\n",
       "  'cslymphn',\n",
       "  239): array(['0', '100', '110', '200', '210', '220', '300', '400', '410', '420',\n",
       "        '430', '450', '460', '470', '480', '50', '800', '999'], dtype='<U3'),\n",
       " (9,\n",
       "  'csmetsdx',\n",
       "  257): array(['0', '10', '11', '12', '15', '16', '18', '20', '23', '26', '27',\n",
       "        '29', '31', '33', '35', '36', '40', '45', '48', '5', '50', '55',\n",
       "        '60', '8', '99'], dtype='<U2'),\n",
       " (10,\n",
       "  'cstseval',\n",
       "  282): array(['0.0', '1.0', '2.0', '3.0', '5.0', '6.0', '9.0'], dtype='<U3'),\n",
       " (11,\n",
       "  'csrgeval',\n",
       "  289): array(['0.0', '1.0', '2.0', '3.0', '5.0', '6.0', '9.0'], dtype='<U3'),\n",
       " (12,\n",
       "  'csmteval',\n",
       "  296): array(['0.0', '1.0', '2.0', '3.0', '5.0', '6.0', '9.0'], dtype='<U3'),\n",
       " (13,\n",
       "  'surgprif',\n",
       "  303): array(['0', '10', '11', '12', '13', '14', '20', '21', '22', '23', '24',\n",
       "        '25', '26', '27', '28', '29', '30', '31', '32', '40', '41', '50',\n",
       "        '51', '55', '56', '57', '60', '61', '65', '66', '70', '80', '90',\n",
       "        '99'], dtype='<U2'),\n",
       " (14,\n",
       "  'no_surg',\n",
       "  337): array(['0', '1', '2', '5', '6', '7', '8', '9'], dtype='<U1'),\n",
       " (15, 'summ2k', 345): array(['0', '1', '2', '7', '9'], dtype='<U1'),\n",
       " (16,\n",
       "  'reg',\n",
       "  350): array(['1501', '1502', '1520', '1521', '1522', '1523', '1525', '1526',\n",
       "        '1527', '1529', '1531', '1535', '1537', '1541', '1542', '1543',\n",
       "        '1544', '1547'], dtype='<U4')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281810, 375)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_rank(array):\n",
    "    codes = None\n",
    "    if race == \"white\":\n",
    "        codes = white_codes\n",
    "    elif race == \"hispanic\":\n",
    "        codes = hispanic_codes\n",
    "    elif race == \"mixed\":\n",
    "        codes = mixed_codes\n",
    "        \n",
    "    array = np.abs(array)\n",
    "    \n",
    "    ranking = {}\n",
    "    ranking['race'] array[-1]\n",
    "    ranking['tumsiz'] = array[-2]\n",
    "    ranking['maligcount'] = array[-3]\n",
    "    ranking['eod10_pn'] = array[-4]\n",
    "    ranking['age_dx'] = array[-5]\n",
    "    \n",
    "    for key, val in codes.items():\n",
    "        varname = key[1]\n",
    "        start_idx = key[2]\n",
    "        end_idx = start_idx + len(val)\n",
    "        ranking[varname] = np.sum(array[start_idx:end_idx])\n",
    "    \n",
    "    d_view = [(name, score) for name,score in ranking.items()]\n",
    "    d_view.sort(key=lambda x:x[1], reverse=True)\n",
    "    for pair in d_view:\n",
    "        print(pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# min_sample_split: 300,400\n",
    "# min_samples_leaf: 200\n",
    "# max_depth: 130\n",
    "# min_weight_fraction_leaf: .01\n",
    "param_grid = [{'max_depth':[40,50,60], 'min_samples_leaf':[250,260,270,280,290]}]\n",
    "tree_clf_reg = DecisionTreeClassifier()\n",
    "dt_grid_search = GridSearchCV(tree_clf_reg, param_grid, cv=3, scoring=make_scorer(roc_auc_score), verbose=3)\n",
    "dt_grid_search.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = dt_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(dt_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(dt_grid_search, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_h = DecisionTreeClassifier(max_features=200, min_samples_leaf=150)\n",
    "tree_clf_h.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(tree_clf_h, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(tree_clf_h.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(tree_clf_h.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(knn_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = [{'C':[.01, .1, .75, 1, 1.5, 2]}]\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3, \n",
    "                              scoring=make_scorer(roc_auc_score), verbose=5\n",
    "                             )\n",
    "lr_grid_search.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = lr_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(lr_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(lr_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.854943791517629\n",
      "ROC: 0.708248205947369\n",
      "PPV: 0.8820798172237166\n",
      "NPV: 0.678562874251497\n",
      "Sensitivity: 0.9469124569801021\n",
      "Specificity: 0.46958395491463617\n",
      "G-Mean: 0.6668244870328711\n",
      "Confusion matrix:\n",
      "[[ 2833  3200]\n",
      " [ 1342 23937]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(X_train, Y_train.astype(int))\n",
    "results(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.05921002491757239\n",
      "1 0.4400121407717491\n",
      "2 -0.07727917526832771\n",
      "3 -0.15110454729288086\n",
      "4 -0.17343587167325278\n",
      "5 -0.09212470587922382\n",
      "6 -0.045966895005032544\n",
      "7 0.0402837571667663\n",
      "8 -0.2243146398519068\n",
      "9 0.13672838592436806\n",
      "10 0.015549776076402712\n",
      "11 0.006784764739845687\n",
      "12 0.8097705622692519\n",
      "13 -0.024456217728319515\n",
      "14 0.3105801391656702\n",
      "15 -0.011756896543885354\n",
      "16 0.0816764410337821\n",
      "17 0.07137002598472987\n",
      "18 -0.08287803282807099\n",
      "19 0.2811580677109233\n",
      "20 0.28662706188327924\n",
      "21 0.3390664646919436\n",
      "22 -0.7512164474149851\n",
      "23 -0.07464683877085512\n",
      "24 0.5063027696766356\n",
      "25 0.1399605441615723\n",
      "26 0.22672983031639116\n",
      "27 -0.5228619406344504\n",
      "28 0.18552806125480403\n",
      "29 -0.16594785991769603\n",
      "30 -1.2317409903844865\n",
      "31 0.6648383594381505\n",
      "32 -0.9068503596322302\n",
      "33 -1.020417016036565\n",
      "34 0.15859071454112258\n",
      "35 0.09677475711534174\n",
      "36 -0.43636014204040163\n",
      "37 -0.5971576404394431\n",
      "38 -1.0179615783970868\n",
      "39 -0.6035996563165054\n",
      "40 -0.2064402823023212\n",
      "41 -0.9515392760563707\n",
      "42 -0.8385108472339524\n",
      "43 0.33883388349208354\n",
      "44 1.6130061192163132\n",
      "45 0.35259875888549747\n",
      "46 0.31790701927463805\n",
      "47 0.861083455865009\n",
      "48 0.46717654060608105\n",
      "49 0.27350957555122174\n",
      "50 0.4318300150316402\n",
      "51 0.0855368342393082\n",
      "52 -0.611825054896104\n",
      "53 0.5750993877700511\n",
      "54 0.6473653329616427\n",
      "55 0.06822301539741178\n",
      "56 0.44956341713158776\n",
      "57 0.23580492746203696\n",
      "58 -0.48735154772103817\n",
      "59 -1.2170798285043674\n",
      "60 0.6053592214565553\n",
      "61 0.23768691136556502\n",
      "62 -0.6961169101365018\n",
      "63 -0.9967898350567328\n",
      "64 0.20396917015456167\n",
      "65 -0.13750613157799926\n",
      "66 0.7417908660869947\n",
      "67 -0.24704526309902458\n",
      "68 -0.42547803071195356\n",
      "69 -0.5737618285739742\n",
      "70 -0.18745795193899822\n",
      "71 0.4474020949829834\n",
      "72 0.33356418022692286\n",
      "73 1.6445307470542287\n",
      "74 0.36300463210046235\n",
      "75 -0.19163694270415893\n",
      "76 -0.7620693159614986\n",
      "77 -0.037049508590198246\n",
      "78 -0.09599321883042405\n",
      "79 0.47349598113476743\n",
      "80 -0.7490077032023553\n",
      "81 0.09614822188628644\n",
      "82 -0.44856649558643463\n",
      "83 -0.5090096316615165\n",
      "84 -0.3510060542127844\n",
      "85 -0.598187355306621\n",
      "86 0.06375517958714486\n",
      "87 -1.282355916175272\n",
      "88 0.04440696066834621\n",
      "89 0.5858386102665574\n",
      "90 1.855060585403153\n",
      "91 0.5738815888197044\n",
      "92 0.9279210480546587\n",
      "93 -0.10172128902690131\n",
      "94 -0.8501444984565414\n",
      "95 -0.1400209146136956\n",
      "96 0.593357816461438\n",
      "97 0.04640196140954707\n",
      "98 -0.5644645175260247\n",
      "99 -0.6711684947877363\n",
      "100 -0.8226121241921593\n",
      "101 -0.8252800508042251\n",
      "102 0.02595007677612746\n",
      "103 0.5731390210073858\n",
      "104 -0.44927811818454627\n",
      "105 0.569022428041656\n",
      "106 -0.5829281817269737\n",
      "107 -0.42229588147169883\n",
      "108 -1.179785043782572\n",
      "109 -0.7104877934029269\n",
      "110 0.17395433198987262\n",
      "111 0.09766769230858834\n",
      "112 -0.00018395360387872021\n",
      "113 -0.8374046039140035\n",
      "114 0.09170050381742914\n",
      "115 0.01625235212824242\n",
      "116 0.09063574169049961\n",
      "117 -1.035610256757996\n",
      "118 0.02776072578847316\n",
      "119 0.6562851260102018\n",
      "120 0.4728373889860178\n",
      "121 0.55813915694029\n",
      "122 0.03180033591918994\n",
      "123 -0.2872939286359764\n",
      "124 0.284313632358786\n",
      "125 -0.025813935816224386\n",
      "126 -0.9381907538418944\n",
      "127 0.6173331419357722\n",
      "128 0.38403734983968785\n",
      "129 0.22290026341821803\n",
      "130 0.8332949358632442\n",
      "131 0.578935903088852\n",
      "132 0.02064007415283827\n",
      "133 0.6666871453969091\n",
      "134 0.10019878366130093\n",
      "135 -0.21612589912392383\n",
      "136 -0.0892627639590878\n",
      "137 -0.11466088536762703\n",
      "138 0.01761311237446149\n",
      "139 0.7097964585120132\n",
      "140 0.1791539143148373\n",
      "141 -0.5191936978931043\n",
      "142 0.034858708792478404\n",
      "143 1.7670062740741215\n",
      "144 -0.2940243478798391\n",
      "145 0.46164507655560016\n",
      "146 0.11681505033862946\n",
      "147 -0.09583600541915949\n",
      "148 0.039892315285765464\n",
      "149 0.09827441972162246\n",
      "150 0.9426809174808319\n",
      "151 -0.629631081640277\n",
      "152 0.39736362476515036\n",
      "153 -0.26045706939010255\n",
      "154 0.01658204798636979\n",
      "155 0.9456280624615608\n",
      "156 0.12250892968298982\n",
      "157 0.575308969008762\n",
      "158 0.1726581823857109\n",
      "159 0.05580917065809847\n",
      "160 0.9391945761568811\n",
      "161 0.5822424045709917\n",
      "162 0.043451122948665266\n",
      "163 0.4367752077788148\n",
      "164 0.30500728300489477\n",
      "165 -0.11772704696268546\n",
      "166 -0.1986755824735037\n",
      "167 0.2003136654276752\n",
      "168 -0.7052884943456571\n",
      "169 -0.6146217268321305\n",
      "170 -0.6364610523065414\n",
      "171 5.545576197584324\n",
      "172 -0.7077600315744947\n",
      "173 -0.26718627043231363\n",
      "174 -0.4979829580766968\n",
      "175 -1.4905821364220917\n",
      "176 0.0729018277326794\n",
      "177 0.5093405768375389\n",
      "178 0.42528602276838723\n",
      "179 0.5190289267298696\n",
      "180 1.0394224310844746\n",
      "181 1.4708550919748555\n",
      "182 0.6611459963763591\n",
      "183 0.26617320263798355\n",
      "184 0.09778680838029344\n",
      "185 0.7029549472039432\n",
      "186 0.4598984928723697\n",
      "187 0.2761778026569779\n",
      "188 0.035845552126378605\n",
      "189 0.08052077095397671\n",
      "190 0.552541059360618\n",
      "191 0.23481330928790567\n",
      "192 0.35598309152670293\n",
      "193 0.0026640614256909353\n",
      "194 -0.25500445868687177\n",
      "195 0.13890719279703528\n",
      "196 0.06701072979801809\n",
      "197 0.015652208717358406\n",
      "198 0.13658912303585535\n",
      "199 0.08940657179265502\n",
      "200 -0.044096072775596386\n",
      "201 -0.4606713007917597\n",
      "202 0.07281992358677628\n",
      "203 0.010841657536278339\n",
      "204 0.036922476905547175\n",
      "205 0.16238002673916668\n",
      "206 0.08024088861360698\n",
      "207 -0.025056396187244458\n",
      "208 -0.10763360164932725\n",
      "209 0.20809551032969603\n",
      "210 0.03894423450704138\n",
      "211 -0.46253312213395853\n",
      "212 0.06227915241179159\n",
      "213 0.1767407487292521\n",
      "214 0.056781769142233846\n",
      "215 0.2288417248239104\n",
      "216 0.6452373396777009\n",
      "217 0.5609188333891518\n",
      "218 -0.47987198637544715\n",
      "219 -0.6375608869293481\n",
      "220 -0.6365345280504154\n",
      "221 -0.6073114649845461\n",
      "222 -0.6516301528421174\n",
      "223 -0.652836259726134\n",
      "224 0.5474644688999785\n",
      "225 -0.57713171036716\n",
      "226 -0.8097367249194177\n",
      "227 -0.6849376107611902\n",
      "228 -1.2812470860761143\n",
      "229 -0.10811469956266685\n",
      "230 -0.5398422964743221\n",
      "231 -0.2582585987095514\n",
      "232 -0.2212206860193162\n",
      "233 -0.14260724355749435\n",
      "234 0.038300520340043394\n",
      "235 -0.2860599112679976\n",
      "236 -0.39343657365771556\n",
      "237 -0.4731377810006289\n",
      "238 -0.30947593755060687\n",
      "239 0.5412209780001832\n",
      "240 0.05270456639902912\n",
      "241 0.5397472352241852\n",
      "242 0.3110289374250967\n",
      "243 0.14107369654954288\n",
      "244 0.27706573118694655\n",
      "245 0.13885889802057721\n",
      "246 0.15069721336327838\n",
      "247 0.373365421790005\n",
      "248 0.16738906258919803\n",
      "249 0.2858175056057036\n",
      "250 0.33659528966506336\n",
      "251 -0.666504968528071\n",
      "252 0.24583539725938502\n",
      "253 -0.7778402735956577\n",
      "254 -0.1994614386228119\n",
      "255 -0.8911693220360339\n",
      "256 -0.41245285876596305\n",
      "257 0.17272049461912894\n",
      "258 0.4329275053265026\n",
      "259 0.4217374727982946\n",
      "260 0.3281735685621025\n",
      "261 0.442808864339195\n",
      "262 0.3647515600775136\n",
      "263 0.2650485233491839\n",
      "264 0.48229535625000036\n",
      "265 -0.06635223101893599\n",
      "266 0.43810127945791605\n",
      "267 0.6010317079485119\n",
      "268 1.2375719767256415\n",
      "269 0.10416082464762642\n",
      "270 -0.20107332069475897\n",
      "271 0.04323102312606702\n",
      "272 -1.095432034559147\n",
      "273 0.3103739212997239\n",
      "274 0.43931580776307005\n",
      "275 -1.0324231714184144\n",
      "276 -0.46681758919871646\n",
      "277 -0.39687757172211463\n",
      "278 -0.30054960015436444\n",
      "279 -0.3486547272119937\n",
      "280 -0.46891077380697144\n",
      "281 -0.39674548743411\n",
      "282 -0.11461188416013264\n",
      "283 0.03554003163560453\n",
      "284 0.200722341663399\n",
      "285 0.05552536036090356\n",
      "286 0.13756237052120443\n",
      "287 0.02173427002469563\n",
      "288 0.3074817763810698\n",
      "289 -0.18389561267936305\n",
      "290 0.08656302074209943\n",
      "291 -0.16385253021030205\n",
      "292 0.039853649817260896\n",
      "293 -0.09491579049289278\n",
      "294 0.16245817397387274\n",
      "295 0.37925351147986425\n",
      "296 0.33572708184525896\n",
      "297 -0.03283056965351521\n",
      "298 -0.05973634024582094\n",
      "299 -0.1159120215954471\n",
      "300 0.49793372798914304\n",
      "301 -0.0687810876783627\n",
      "302 0.25160996506934274\n",
      "303 0.20830555685543303\n",
      "304 -0.08772627329389332\n",
      "305 -0.30781548226590316\n",
      "306 -0.3414478202047486\n",
      "307 0.347646363626964\n",
      "308 -0.7589771310104856\n",
      "309 -0.9544411035695286\n",
      "310 0.35702041123569206\n",
      "311 -0.040336572652325875\n",
      "312 0.7896122712896763\n",
      "313 0.2024813399730073\n",
      "314 0.1643640507810958\n",
      "315 0.00825191775817404\n",
      "316 0.12448867581683043\n",
      "317 0.25817341552867606\n",
      "318 -0.06936259919378678\n",
      "319 0.18732785350570258\n",
      "320 0.5813489932444474\n",
      "321 0.22360743787801132\n",
      "322 0.2253384129961255\n",
      "323 0.06518010322306453\n",
      "324 0.21276969316462382\n",
      "325 0.08556346411585061\n",
      "326 -0.06954267886240788\n",
      "327 -0.3169090618177962\n",
      "328 -0.6128674028367764\n",
      "329 0.42042058975370256\n",
      "330 -0.025311806961232936\n",
      "331 -0.15232783522556156\n",
      "332 0.09748155144724417\n",
      "333 -0.14735164930814013\n",
      "334 0.06281097315537297\n",
      "335 0.11226187328150598\n",
      "336 -0.03922366122851657\n",
      "337 -0.21902633234083027\n",
      "338 0.1544852726867786\n",
      "339 0.779023736638092\n",
      "340 -0.002788506100413651\n",
      "341 -0.13824224223639717\n",
      "342 -0.24365137767684567\n",
      "343 0.18157316438350066\n",
      "344 -0.14655277876276818\n",
      "345 0.5271768670654033\n",
      "346 -0.33084533625286333\n",
      "347 0.5822424045709917\n",
      "348 0.5336932988729989\n",
      "349 0.18804696886779446\n",
      "350 -0.7087007683836165\n",
      "351 0.03041162294474344\n",
      "352 0.02760676199174434\n",
      "353 0.3150862954386543\n",
      "354 0.019760087846739223\n",
      "355 0.04985763258709744\n",
      "356 -0.013486380946356678\n",
      "357 -0.058334251574737345\n",
      "358 0.043804894880278486\n",
      "359 -0.14398605002353795\n",
      "360 0.008927585301325217\n",
      "361 0.3872169958561487\n",
      "362 0.10358075819236734\n",
      "363 0.01267654091137739\n",
      "364 -0.014614323905511088\n",
      "365 -0.05211134578624628\n",
      "366 -0.10298928571717507\n",
      "367 -0.04932647386303631\n",
      "368 0.1828413831805734\n",
      "369 -0.0908172973013669\n",
      "370 -0.5142053306015647\n",
      "371 -0.25863121493881913\n",
      "372 0.06687015312192104\n",
      "373 -0.06339479948517054\n",
      "374 0.015190134137155687\n"
     ]
    }
   ],
   "source": [
    "for key, val in enumerate(lr.coef_[0]):\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(171, 5.545576197584324),\n",
       " (90, 1.855060585403153),\n",
       " (143, 1.7670062740741215),\n",
       " (73, 1.6445307470542287),\n",
       " (44, 1.6130061192163132),\n",
       " (181, 1.4708550919748555),\n",
       " (268, 1.2375719767256415),\n",
       " (180, 1.0394224310844746),\n",
       " (155, 0.9456280624615608),\n",
       " (150, 0.9426809174808319),\n",
       " (160, 0.9391945761568811),\n",
       " (92, 0.9279210480546587),\n",
       " (47, 0.861083455865009),\n",
       " (130, 0.8332949358632442),\n",
       " (12, 0.8097705622692519),\n",
       " (312, 0.7896122712896763),\n",
       " (339, 0.779023736638092),\n",
       " (66, 0.7417908660869947),\n",
       " (139, 0.7097964585120132),\n",
       " (185, 0.7029549472039432),\n",
       " (133, 0.6666871453969091),\n",
       " (31, 0.6648383594381505),\n",
       " (182, 0.6611459963763591),\n",
       " (119, 0.6562851260102018),\n",
       " (54, 0.6473653329616427),\n",
       " (216, 0.6452373396777009),\n",
       " (127, 0.6173331419357722),\n",
       " (60, 0.6053592214565553),\n",
       " (267, 0.6010317079485119),\n",
       " (96, 0.593357816461438),\n",
       " (89, 0.5858386102665574),\n",
       " (161, 0.5822424045709917),\n",
       " (347, 0.5822424045709917),\n",
       " (320, 0.5813489932444474),\n",
       " (131, 0.578935903088852),\n",
       " (157, 0.575308969008762),\n",
       " (53, 0.5750993877700511),\n",
       " (91, 0.5738815888197044),\n",
       " (103, 0.5731390210073858),\n",
       " (105, 0.569022428041656),\n",
       " (217, 0.5609188333891518),\n",
       " (121, 0.55813915694029),\n",
       " (190, 0.552541059360618),\n",
       " (224, 0.5474644688999785),\n",
       " (239, 0.5412209780001832),\n",
       " (241, 0.5397472352241852),\n",
       " (348, 0.5336932988729989),\n",
       " (345, 0.5271768670654033),\n",
       " (179, 0.5190289267298696),\n",
       " (177, 0.5093405768375389),\n",
       " (24, 0.5063027696766356),\n",
       " (300, 0.49793372798914304),\n",
       " (264, 0.48229535625000036),\n",
       " (79, 0.47349598113476743),\n",
       " (120, 0.4728373889860178),\n",
       " (48, 0.46717654060608105),\n",
       " (145, 0.46164507655560016),\n",
       " (186, 0.4598984928723697),\n",
       " (56, 0.44956341713158776),\n",
       " (71, 0.4474020949829834),\n",
       " (261, 0.442808864339195),\n",
       " (1, 0.4400121407717491),\n",
       " (274, 0.43931580776307005),\n",
       " (266, 0.43810127945791605),\n",
       " (163, 0.4367752077788148),\n",
       " (258, 0.4329275053265026),\n",
       " (50, 0.4318300150316402),\n",
       " (178, 0.42528602276838723),\n",
       " (259, 0.4217374727982946),\n",
       " (329, 0.42042058975370256),\n",
       " (152, 0.39736362476515036),\n",
       " (361, 0.3872169958561487),\n",
       " (128, 0.38403734983968785),\n",
       " (295, 0.37925351147986425),\n",
       " (247, 0.373365421790005),\n",
       " (262, 0.3647515600775136),\n",
       " (74, 0.36300463210046235),\n",
       " (310, 0.35702041123569206),\n",
       " (192, 0.35598309152670293),\n",
       " (45, 0.35259875888549747),\n",
       " (307, 0.347646363626964),\n",
       " (21, 0.3390664646919436),\n",
       " (43, 0.33883388349208354),\n",
       " (250, 0.33659528966506336),\n",
       " (296, 0.33572708184525896),\n",
       " (72, 0.33356418022692286),\n",
       " (260, 0.3281735685621025),\n",
       " (46, 0.31790701927463805),\n",
       " (353, 0.3150862954386543),\n",
       " (242, 0.3110289374250967),\n",
       " (14, 0.3105801391656702),\n",
       " (273, 0.3103739212997239),\n",
       " (288, 0.3074817763810698),\n",
       " (164, 0.30500728300489477),\n",
       " (20, 0.28662706188327924),\n",
       " (249, 0.2858175056057036),\n",
       " (124, 0.284313632358786),\n",
       " (19, 0.2811580677109233),\n",
       " (244, 0.27706573118694655),\n",
       " (187, 0.2761778026569779),\n",
       " (49, 0.27350957555122174),\n",
       " (183, 0.26617320263798355),\n",
       " (263, 0.2650485233491839),\n",
       " (317, 0.25817341552867606),\n",
       " (302, 0.25160996506934274),\n",
       " (252, 0.24583539725938502),\n",
       " (61, 0.23768691136556502),\n",
       " (57, 0.23580492746203696),\n",
       " (191, 0.23481330928790567),\n",
       " (215, 0.2288417248239104),\n",
       " (26, 0.22672983031639116),\n",
       " (322, 0.2253384129961255),\n",
       " (321, 0.22360743787801132),\n",
       " (129, 0.22290026341821803),\n",
       " (324, 0.21276969316462382),\n",
       " (303, 0.20830555685543303),\n",
       " (209, 0.20809551032969603),\n",
       " (64, 0.20396917015456167),\n",
       " (313, 0.2024813399730073),\n",
       " (284, 0.200722341663399),\n",
       " (167, 0.2003136654276752),\n",
       " (349, 0.18804696886779446),\n",
       " (319, 0.18732785350570258),\n",
       " (28, 0.18552806125480403),\n",
       " (368, 0.1828413831805734),\n",
       " (343, 0.18157316438350066),\n",
       " (140, 0.1791539143148373),\n",
       " (213, 0.1767407487292521),\n",
       " (110, 0.17395433198987262),\n",
       " (257, 0.17272049461912894),\n",
       " (158, 0.1726581823857109),\n",
       " (248, 0.16738906258919803),\n",
       " (314, 0.1643640507810958),\n",
       " (294, 0.16245817397387274),\n",
       " (205, 0.16238002673916668),\n",
       " (34, 0.15859071454112258),\n",
       " (338, 0.1544852726867786),\n",
       " (246, 0.15069721336327838),\n",
       " (243, 0.14107369654954288),\n",
       " (25, 0.1399605441615723),\n",
       " (195, 0.13890719279703528),\n",
       " (245, 0.13885889802057721),\n",
       " (286, 0.13756237052120443),\n",
       " (9, 0.13672838592436806),\n",
       " (198, 0.13658912303585535),\n",
       " (316, 0.12448867581683043),\n",
       " (156, 0.12250892968298982),\n",
       " (146, 0.11681505033862946),\n",
       " (335, 0.11226187328150598),\n",
       " (269, 0.10416082464762642),\n",
       " (362, 0.10358075819236734),\n",
       " (134, 0.10019878366130093),\n",
       " (149, 0.09827441972162246),\n",
       " (184, 0.09778680838029344),\n",
       " (111, 0.09766769230858834),\n",
       " (332, 0.09748155144724417),\n",
       " (35, 0.09677475711534174),\n",
       " (81, 0.09614822188628644),\n",
       " (114, 0.09170050381742914),\n",
       " (116, 0.09063574169049961),\n",
       " (199, 0.08940657179265502),\n",
       " (290, 0.08656302074209943),\n",
       " (325, 0.08556346411585061),\n",
       " (51, 0.0855368342393082),\n",
       " (16, 0.0816764410337821),\n",
       " (189, 0.08052077095397671),\n",
       " (206, 0.08024088861360698),\n",
       " (176, 0.0729018277326794),\n",
       " (202, 0.07281992358677628),\n",
       " (17, 0.07137002598472987),\n",
       " (55, 0.06822301539741178),\n",
       " (196, 0.06701072979801809),\n",
       " (372, 0.06687015312192104),\n",
       " (323, 0.06518010322306453),\n",
       " (86, 0.06375517958714486),\n",
       " (334, 0.06281097315537297),\n",
       " (212, 0.06227915241179159),\n",
       " (214, 0.056781769142233846),\n",
       " (159, 0.05580917065809847),\n",
       " (285, 0.05552536036090356),\n",
       " (240, 0.05270456639902912),\n",
       " (355, 0.04985763258709744),\n",
       " (97, 0.04640196140954707),\n",
       " (88, 0.04440696066834621),\n",
       " (358, 0.043804894880278486),\n",
       " (162, 0.043451122948665266),\n",
       " (271, 0.04323102312606702),\n",
       " (7, 0.0402837571667663),\n",
       " (148, 0.039892315285765464),\n",
       " (292, 0.039853649817260896),\n",
       " (210, 0.03894423450704138),\n",
       " (234, 0.038300520340043394),\n",
       " (204, 0.036922476905547175),\n",
       " (188, 0.035845552126378605),\n",
       " (283, 0.03554003163560453),\n",
       " (142, 0.034858708792478404),\n",
       " (122, 0.03180033591918994),\n",
       " (351, 0.03041162294474344),\n",
       " (118, 0.02776072578847316),\n",
       " (352, 0.02760676199174434),\n",
       " (102, 0.02595007677612746),\n",
       " (287, 0.02173427002469563),\n",
       " (132, 0.02064007415283827),\n",
       " (354, 0.019760087846739223),\n",
       " (138, 0.01761311237446149),\n",
       " (154, 0.01658204798636979),\n",
       " (115, 0.01625235212824242),\n",
       " (197, 0.015652208717358406),\n",
       " (10, 0.015549776076402712),\n",
       " (374, 0.015190134137155687),\n",
       " (363, 0.01267654091137739),\n",
       " (203, 0.010841657536278339),\n",
       " (360, 0.008927585301325217),\n",
       " (315, 0.00825191775817404),\n",
       " (11, 0.006784764739845687),\n",
       " (193, 0.0026640614256909353),\n",
       " (112, -0.00018395360387872021),\n",
       " (340, -0.002788506100413651),\n",
       " (15, -0.011756896543885354),\n",
       " (356, -0.013486380946356678),\n",
       " (364, -0.014614323905511088),\n",
       " (13, -0.024456217728319515),\n",
       " (207, -0.025056396187244458),\n",
       " (330, -0.025311806961232936),\n",
       " (125, -0.025813935816224386),\n",
       " (297, -0.03283056965351521),\n",
       " (77, -0.037049508590198246),\n",
       " (336, -0.03922366122851657),\n",
       " (311, -0.040336572652325875),\n",
       " (200, -0.044096072775596386),\n",
       " (6, -0.045966895005032544),\n",
       " (367, -0.04932647386303631),\n",
       " (365, -0.05211134578624628),\n",
       " (357, -0.058334251574737345),\n",
       " (0, -0.05921002491757239),\n",
       " (298, -0.05973634024582094),\n",
       " (373, -0.06339479948517054),\n",
       " (265, -0.06635223101893599),\n",
       " (301, -0.0687810876783627),\n",
       " (318, -0.06936259919378678),\n",
       " (326, -0.06954267886240788),\n",
       " (23, -0.07464683877085512),\n",
       " (2, -0.07727917526832771),\n",
       " (18, -0.08287803282807099),\n",
       " (304, -0.08772627329389332),\n",
       " (136, -0.0892627639590878),\n",
       " (369, -0.0908172973013669),\n",
       " (5, -0.09212470587922382),\n",
       " (293, -0.09491579049289278),\n",
       " (147, -0.09583600541915949),\n",
       " (78, -0.09599321883042405),\n",
       " (93, -0.10172128902690131),\n",
       " (366, -0.10298928571717507),\n",
       " (208, -0.10763360164932725),\n",
       " (229, -0.10811469956266685),\n",
       " (282, -0.11461188416013264),\n",
       " (137, -0.11466088536762703),\n",
       " (299, -0.1159120215954471),\n",
       " (165, -0.11772704696268546),\n",
       " (65, -0.13750613157799926),\n",
       " (341, -0.13824224223639717),\n",
       " (95, -0.1400209146136956),\n",
       " (233, -0.14260724355749435),\n",
       " (359, -0.14398605002353795),\n",
       " (344, -0.14655277876276818),\n",
       " (333, -0.14735164930814013),\n",
       " (3, -0.15110454729288086),\n",
       " (331, -0.15232783522556156),\n",
       " (291, -0.16385253021030205),\n",
       " (29, -0.16594785991769603),\n",
       " (4, -0.17343587167325278),\n",
       " (289, -0.18389561267936305),\n",
       " (70, -0.18745795193899822),\n",
       " (75, -0.19163694270415893),\n",
       " (166, -0.1986755824735037),\n",
       " (254, -0.1994614386228119),\n",
       " (270, -0.20107332069475897),\n",
       " (40, -0.2064402823023212),\n",
       " (135, -0.21612589912392383),\n",
       " (337, -0.21902633234083027),\n",
       " (232, -0.2212206860193162),\n",
       " (8, -0.2243146398519068),\n",
       " (342, -0.24365137767684567),\n",
       " (67, -0.24704526309902458),\n",
       " (194, -0.25500445868687177),\n",
       " (231, -0.2582585987095514),\n",
       " (371, -0.25863121493881913),\n",
       " (153, -0.26045706939010255),\n",
       " (173, -0.26718627043231363),\n",
       " (235, -0.2860599112679976),\n",
       " (123, -0.2872939286359764),\n",
       " (144, -0.2940243478798391),\n",
       " (278, -0.30054960015436444),\n",
       " (305, -0.30781548226590316),\n",
       " (238, -0.30947593755060687),\n",
       " (327, -0.3169090618177962),\n",
       " (346, -0.33084533625286333),\n",
       " (306, -0.3414478202047486),\n",
       " (279, -0.3486547272119937),\n",
       " (84, -0.3510060542127844),\n",
       " (236, -0.39343657365771556),\n",
       " (281, -0.39674548743411),\n",
       " (277, -0.39687757172211463),\n",
       " (256, -0.41245285876596305),\n",
       " (107, -0.42229588147169883),\n",
       " (68, -0.42547803071195356),\n",
       " (36, -0.43636014204040163),\n",
       " (82, -0.44856649558643463),\n",
       " (104, -0.44927811818454627),\n",
       " (201, -0.4606713007917597),\n",
       " (211, -0.46253312213395853),\n",
       " (276, -0.46681758919871646),\n",
       " (280, -0.46891077380697144),\n",
       " (237, -0.4731377810006289),\n",
       " (218, -0.47987198637544715),\n",
       " (58, -0.48735154772103817),\n",
       " (174, -0.4979829580766968),\n",
       " (83, -0.5090096316615165),\n",
       " (370, -0.5142053306015647),\n",
       " (141, -0.5191936978931043),\n",
       " (27, -0.5228619406344504),\n",
       " (230, -0.5398422964743221),\n",
       " (98, -0.5644645175260247),\n",
       " (69, -0.5737618285739742),\n",
       " (225, -0.57713171036716),\n",
       " (106, -0.5829281817269737),\n",
       " (37, -0.5971576404394431),\n",
       " (85, -0.598187355306621),\n",
       " (39, -0.6035996563165054),\n",
       " (221, -0.6073114649845461),\n",
       " (52, -0.611825054896104),\n",
       " (328, -0.6128674028367764),\n",
       " (169, -0.6146217268321305),\n",
       " (151, -0.629631081640277),\n",
       " (170, -0.6364610523065414),\n",
       " (220, -0.6365345280504154),\n",
       " (219, -0.6375608869293481),\n",
       " (222, -0.6516301528421174),\n",
       " (223, -0.652836259726134),\n",
       " (251, -0.666504968528071),\n",
       " (99, -0.6711684947877363),\n",
       " (227, -0.6849376107611902),\n",
       " (62, -0.6961169101365018),\n",
       " (168, -0.7052884943456571),\n",
       " (172, -0.7077600315744947),\n",
       " (350, -0.7087007683836165),\n",
       " (109, -0.7104877934029269),\n",
       " (80, -0.7490077032023553),\n",
       " (22, -0.7512164474149851),\n",
       " (308, -0.7589771310104856),\n",
       " (76, -0.7620693159614986),\n",
       " (253, -0.7778402735956577),\n",
       " (226, -0.8097367249194177),\n",
       " (100, -0.8226121241921593),\n",
       " (101, -0.8252800508042251),\n",
       " (113, -0.8374046039140035),\n",
       " (42, -0.8385108472339524),\n",
       " (94, -0.8501444984565414),\n",
       " (255, -0.8911693220360339),\n",
       " (32, -0.9068503596322302),\n",
       " (126, -0.9381907538418944),\n",
       " (41, -0.9515392760563707),\n",
       " (309, -0.9544411035695286),\n",
       " (63, -0.9967898350567328),\n",
       " (38, -1.0179615783970868),\n",
       " (33, -1.020417016036565),\n",
       " (275, -1.0324231714184144),\n",
       " (117, -1.035610256757996),\n",
       " (272, -1.095432034559147),\n",
       " (108, -1.179785043782572),\n",
       " (59, -1.2170798285043674),\n",
       " (30, -1.2317409903844865),\n",
       " (228, -1.2812470860761143),\n",
       " (87, -1.282355916175272),\n",
       " (175, -1.4905821364220917)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(lr.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scoring=make_scorer(roc_auc_score)\n",
    "param_grid = [{'max_features':[175,200], 'n_estimators':[10,15,20], 'min_samples_leaf':[150,175,200]}]\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "            param_grid, cv=3, scoring=make_scorer(roc_auc_score), \n",
    "            verbose=5\n",
    ")\n",
    "rf_grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rf_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(rf_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=20, min_samples_leaf=300, max_features=225, random_state=97)\n",
    "rf_clf.fit(X_train, Y_train)\n",
    "results(rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(rf_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(rf_clf.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(rf_grid_search, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_clf = LinearSVC(C=.01)\n",
    "svm_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(svm_clf, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(svm_clf.coef_[0], \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(svm_clf.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "clf1 = RandomForestClassifier(n_estimators=20, min_samples_leaf=300, max_features=225)\n",
    "clf2 = LogisticRegression(C=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = GaussianMixture()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[\n",
    "    ('rf', clf1), ('lr', clf2), ('nb', clf3), ('gm', clf4)\n",
    "], voting='soft')\n",
    "eclf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(eclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_clf = GaussianMixture().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
