{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = \"hispanic\"\n",
    "#race = \"white\"\n",
    "#race = \"mixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../Data/' + race + '/X.npy')\n",
    "Y2 = np.load('../Data/' + race + '/Y2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0.0, ..., 0, 4, 30],\n",
       "       [0.0, 0.0, 0.0, ..., 0, 2, 30],\n",
       "       [0.0, 1.0, 0.0, ..., 0, 3, 24.65625],\n",
       "       ...,\n",
       "       [0.0, 1.0, 0.0, ..., 0, 1, 55],\n",
       "       [0.0, 0.0, 0.0, ..., 0.031280517578125, 1, 76.30078125],\n",
       "       [0.0, 1.0, 0.0, ..., 0.569580078125, 1, 21]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_hispanic = np.load('../Data/hispanic/X.npy')\n",
    "# Y_hispanic = np.load('../Data/hispanic/Y2.npy')\n",
    "# X_white = np.load('../Data/white/X.npy')\n",
    "# Y_white = np.load('../Data/white/Y2.npy')\n",
    "#X_mixed = np.load('../Data/mixed/X.npy')\n",
    "#Y_mixed = np.load('../Data/mixed/Y2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(X, Y):\n",
    "    # shuffle\n",
    "    np.random.seed(97)\n",
    "    idx = np.random.permutation(len(X))\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "    \n",
    "    #X = X[:size_hispanic]\n",
    "    #Y = Y[:size_hispanic]\n",
    "\n",
    "    # split into training and test sets\n",
    "    TEST_SET_SIZE = int(0.1*len(Y))\n",
    "    X_train, X_test = X[:-TEST_SET_SIZE], X[-TEST_SET_SIZE:]\n",
    "    Y_train, Y_test = Y[:-TEST_SET_SIZE].astype(int), Y[-TEST_SET_SIZE:].astype(int)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = split_train_test(X, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train_h, X_test_h, Y_train_h, Y_test_h = split_train_test(X_hispanic, Y_hispanic)\n",
    "#X_train_w, X_test_w, Y_train_w, Y_test_w = split_train_test(X_white, Y_white)\n",
    "#X_train_m, X_test_m, Y_train_m, Y_test_m = split_train_test(X_mixed, Y_mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "Fit scaler based on training data, then transform both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# feature scaling: scale features based on training data only\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def feature_scale(X_train, X_test):\n",
    "    \n",
    "    mm_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    X_train[:,:-4] = mm_scaler.fit_transform(X_train[:,:-4])\n",
    "    X_test[:,:-4] = mm_scaler.transform(X_test[:,:-4])\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train[:,-4:] = std_scaler.fit_transform(X_train[:,-4:])\n",
    "    X_test[:,-4:] = std_scaler.transform(X_test[:,-4:])\n",
    "    return X_train, X_test\n",
    "    \n",
    "    #mm_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    #X_train[:,-4:] = mm_scaler.fit_transform(X_train[:,-4:])\n",
    "    #X_test[:,-4:] = mm_scaler.transform(X_test[:,-4:])\n",
    "    \n",
    "    #std_scaler = StandardScaler()\n",
    "    #X_train[:,:-4] = std_scaler.fit_transform(X_train[:,:-4])\n",
    "    #X_test[:,:-4] = std_scaler.transform(X_test[:,:-4])\n",
    "    #return X_train, X_test\n",
    "\n",
    "X_train, X_test = feature_scale(X_train, X_test)\n",
    "#X_train_h, X_test_h = feature_scale(X_train_h, X_test_h)\n",
    "#X_train_w, X_test_w = feature_scale(X_train_w, X_test_w)\n",
    "#X_train_m, X_test_m = feature_scale(X_train_m, X_test_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def results(classifier):\n",
    "    Y_pred_test = classifier.predict(X_test)\n",
    "    print(\"Test accuracy score: \" + str(accuracy_score(Y_test.astype(int), Y_pred_test)))\n",
    "    print(\"ROC: \" + str(roc_auc_score(Y_test, classifier.predict_proba(X_test)[:,1])))\n",
    "    #print(\"ROC: \" + str(roc_auc_score(Y_test, Y_pred_test)))\n",
    "    matrix = confusion_matrix(Y_test.astype(int), Y_pred_test)\n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    ppv = tp/(tp+fp)\n",
    "    npv = tn/(tn+fn)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    g_mean = np.sqrt(sensitivity*specificity)\n",
    "    print(\"PPV: \" + str(ppv))\n",
    "    print(\"NPV: \" + str(npv))\n",
    "    print(\"Sensitivity: \" + str(sensitivity))\n",
    "    print(\"Specificity: \" + str(specificity))\n",
    "    print(\"G-Mean: \" + str(g_mean))\n",
    "    print(\"Confusion matrix:\\n\" + str(matrix))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('white_codes.pkl', 'rb') as f_w:\n",
    "    white_codes = pickle.load(f_w)\n",
    "with open('hispanic_codes.pkl', 'rb') as f_h:\n",
    "    hispanic_codes = pickle.load(f_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hispanic_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_rank(array):\n",
    "    codes = None\n",
    "    if race == \"white\":\n",
    "        codes = white_codes\n",
    "    elif race == \"hispanic\":\n",
    "        codes = hispanic_codes\n",
    "        \n",
    "    array = np.abs(array)\n",
    "    \n",
    "    ranking = {}\n",
    "    ranking['tumsiz'] = array[-1]\n",
    "    ranking['maligcount'] = array[-2]\n",
    "    ranking['eod10_pn'] = array[-3]\n",
    "    ranking['age_dx'] = array[-4]\n",
    "    \n",
    "    for key, val in codes.items():\n",
    "        varname = key[1]\n",
    "        start_idx = key[2]\n",
    "        end_idx = start_idx + len(val)\n",
    "        ranking[varname] = np.sum(array[start_idx:end_idx])\n",
    "    \n",
    "    d_view = [(name, score) for name,score in ranking.items()]\n",
    "    d_view.sort(key=lambda x:x[1], reverse=True)\n",
    "    for rank, pair in enumerate(d_view, 1):\n",
    "        print(rank, pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# min_sample_split: 300,400\n",
    "# min_samples_leaf: 200\n",
    "# max_depth: 130\n",
    "# min_weight_fraction_leaf: .01\n",
    "param_grid = [{'max_depth':[40,50,60], 'min_samples_leaf':[250,260,270,280,290]}]\n",
    "tree_clf_reg = DecisionTreeClassifier()\n",
    "dt_grid_search = GridSearchCV(tree_clf_reg, param_grid, cv=3, scoring=make_scorer(roc_auc_score), verbose=3)\n",
    "dt_grid_search.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = dt_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(dt_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(dt_grid_search, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_h = DecisionTreeClassifier(max_features=200, min_samples_leaf=150)\n",
    "tree_clf_h.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(tree_clf_h, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(tree_clf_h.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(tree_clf_h.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(knn_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = [{'C':[.01, .1, .75, 1, 1.5, 2]}]\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3, \n",
    "                              scoring=make_scorer(roc_auc_score), verbose=5\n",
    "                             )\n",
    "lr_grid_search.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = lr_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(lr_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(lr_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1, class_weight={1:1, 0:2})\n",
    "lr.fit(X_train, Y_train.astype(int))\n",
    "results(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in enumerate(lr.coef_[0]):\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(enumerate(lr.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scoring=make_scorer(roc_auc_score)\n",
    "param_grid = [{'max_features':[175,200], 'n_estimators':[10,15,20], 'min_samples_leaf':[150,175,200]}]\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "            param_grid, cv=3, scoring=make_scorer(roc_auc_score), \n",
    "            verbose=5\n",
    ")\n",
    "rf_grid_search.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rf_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(rf_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=200, min_samples_leaf=150, max_features=200, random_state=42, \n",
    "                               class_weight={1:1, 0:3})\n",
    "rf_clf.fit(X_train_res, Y_train_res)\n",
    "results(rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(rf_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(rf_clf.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(rf_grid_search, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_clf = LinearSVC(C=.01)\n",
    "svm_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(svm_clf, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(svm_clf.coef_[0], \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(svm_clf.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "clf1 = RandomForestClassifier(n_estimators=20, min_samples_leaf=300, max_features=225, class_weight={1:1, 0:5})\n",
    "clf2 = LogisticRegression(C=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, \n",
    "                           algorithm=\"SAMME.R\", learning_rate=1)\n",
    "#clf4 = GaussianMixture()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[\n",
    "    ('rf', clf1), ('lr', clf2), ('nb', clf3), ('ab', clf4)\n",
    "], voting='soft')\n",
    "eclf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, max_samples=3000,\n",
    "                           bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(bag_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "bbc = BalancedBaggingClassifier(DecisionTreeClassifier(), n_estimators=200, max_samples=3000,\n",
    "                           bootstrap=True, n_jobs=-1)\n",
    "bbc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(bbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scoring=make_scorer(roc_auc_score)\n",
    "param_grid = [{\"n_estimators\":[100, 115, 130, 145], \"learning_rate\":[.6, .7, .8, .9, 1]}]\n",
    "ab_grid_search = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME.R\"), \n",
    "            param_grid, cv=3, scoring=make_scorer(roc_auc_score), \n",
    "            verbose=5\n",
    ")\n",
    "ab_grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = ab_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(ab_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(ab_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ab_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, \n",
    "                           algorithm=\"SAMME.R\", learning_rate=1)\n",
    "ab_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(ab_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(ab_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=400,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=400)\n",
    "gb_clf.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.7822730902315678\n",
      "ROC: 0.8611901843439805\n",
      "PPV: 0.943921568627451\n",
      "NPV: 0.4407622203811102\n",
      "Sensitivity: 0.780986372485399\n",
      "Specificity: 0.7881481481481482\n",
      "G-Mean: 0.7845590884078184\n",
      "Confusion matrix:\n",
      "[[ 532  143]\n",
      " [ 675 2407]]\n"
     ]
    }
   ],
   "source": [
    "results(gb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(ratio={0: 20000, 1:27731},random_state=42)\n",
    "X_train_res, Y_train_res = sm.fit_sample(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "us = RandomUnderSampler(ratio={0:Counter(Y_train)[0], 1:Counter(Y_train)[0]})\n",
    "X_train_res, Y_train_res = us.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6087, 1: 6087})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "os = RandomOverSampler(ratio={0:20000, 1:27731})\n",
    "X_train_res, Y_train_res = os.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
