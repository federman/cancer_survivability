{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the group you want to train on\n",
    "#race = \"hispanic\"\n",
    "#race = \"white\"\n",
    "race = \"mixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../Data/' + race + '/X.npy')\n",
    "Y2 = np.load('../Data/' + race + '/Y2.npy')\n",
    "\n",
    "if race == 'mixed':\n",
    "    ethnicity_labels = np.load('../Data/mixed/ethnicity_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 275547, 1: 37575})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(ethnicity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((X,ethnicity_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313122, 373)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(X, Y):\n",
    "    # shuffle\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(len(X))\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "\n",
    "    # split into training and test sets\n",
    "    TEST_SET_SIZE = int(0.1*len(Y))\n",
    "    X_train, X_test = X[:-TEST_SET_SIZE], X[-TEST_SET_SIZE:]\n",
    "    Y_train, Y_test = Y[:-TEST_SET_SIZE].astype(int), Y[-TEST_SET_SIZE:].astype(int)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(X, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281810, 373)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "Fit scaler based on training data, then transform both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/samuel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# feature scaling: scale features based on training data only\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def feature_scale(X_train, X_test):\n",
    "    \n",
    "    mm_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    X_train[:,:-4] = mm_scaler.fit_transform(X_train[:,:-4])\n",
    "    X_test[:,:-4] = mm_scaler.transform(X_test[:,:-4])\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train[:,-4:] = std_scaler.fit_transform(X_train[:,-4:])\n",
    "    X_test[:,-4:] = std_scaler.transform(X_test[:,-4:])\n",
    "    return X_train, X_test\n",
    "\n",
    "X_train, X_test = feature_scale(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def results(classifier, X_test=X_test):\n",
    "    #Y_pred_test = classifier.predict(X_test)\n",
    "    Y_pred_test = classifier.predict(X_test)\n",
    "    print(\"Test accuracy score: \" + str(accuracy_score(Y_test.astype(int), Y_pred_test)))\n",
    "    print(\"ROC: \" + str(roc_auc_score(Y_test, classifier.predict_proba(X_test)[:,1])))\n",
    "    #print(\"ROC: \" + str(roc_auc_score(Y_test, Y_pred_test)))\n",
    "    matrix = confusion_matrix(Y_test.astype(int), Y_pred_test)\n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    ppv = tp/(tp+fp)\n",
    "    npv = tn/(tn+fn)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    g_mean = np.sqrt(sensitivity*specificity)\n",
    "    print(\"PPV: \" + str(ppv))\n",
    "    print(\"NPV: \" + str(npv))\n",
    "    print(\"Sensitivity: \" + str(sensitivity))\n",
    "    print(\"Specificity: \" + str(specificity))\n",
    "    print(\"G-Mean: \" + str(g_mean))\n",
    "    print(\"Confusion matrix:\\n\" + str(matrix))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ethnicity_codes/white_codes.pkl', 'rb') as f_w:\n",
    "    white_codes = pickle.load(f_w)\n",
    "with open('ethnicity_codes/hispanic_codes.pkl', 'rb') as f_h:\n",
    "    hispanic_codes = pickle.load(f_h)\n",
    "with open('ethnicity_codes/mixed_codes.pkl', 'rb')  as f_m:\n",
    "    mixed_codes = pickle.load(f_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_rank(array, ethnicity_label):\n",
    "    codes = None\n",
    "    if race == \"white\":\n",
    "        codes = white_codes\n",
    "    elif race == \"hispanic\":\n",
    "        codes = hispanic_codes\n",
    "    elif race == \"mixed\":\n",
    "        codes = mixed_codes\n",
    "        \n",
    "    array = np.abs(array)\n",
    "    \n",
    "    ranking = {}\n",
    "    if ethnicity_label:\n",
    "        ranking['race'] = array[-1]\n",
    "        ranking['tumsiz'] = array[-2]\n",
    "        ranking['maligcount'] = array[-3]\n",
    "        ranking['eod10_pn'] = array[-4]\n",
    "        ranking['age_dx'] = array[-5]\n",
    "    \n",
    "    else:\n",
    "        ranking['tumsiz'] = array[-1]\n",
    "        ranking['maligcount'] = array[-2]\n",
    "        ranking['eod10_pn'] = array[-3]\n",
    "        ranking['age_dx'] = array[-4]\n",
    "    \n",
    "    for key, val in codes.items():\n",
    "        varname = key[1]\n",
    "        start_idx = key[2]\n",
    "        end_idx = start_idx + len(val)\n",
    "        ranking[varname] = np.sum(array[start_idx:end_idx])\n",
    "    \n",
    "    d_view = [(name, score) for name,score in ranking.items()]\n",
    "    d_view.sort(key=lambda x:x[1], reverse=True)\n",
    "    for rank, pair in enumerate(d_view, 1):\n",
    "        print(rank, pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# min_sample_split: 300,400\n",
    "# min_samples_leaf: 200\n",
    "# max_depth: 130\n",
    "# min_weight_fraction_leaf: .01\n",
    "param_grid = [{'max_depth':[40,50,60], 'min_samples_leaf':[250,260,270,280,290]}]\n",
    "tree_clf_reg = DecisionTreeClassifier()\n",
    "dt_grid_search = GridSearchCV(tree_clf_reg, param_grid, cv=3, scoring=make_scorer(roc_auc_score), verbose=3)\n",
    "dt_grid_search.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = dt_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(dt_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(dt_grid_search, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_h = DecisionTreeClassifier(max_features=200, min_samples_leaf=150)\n",
    "tree_clf_h.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(tree_clf_h, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(tree_clf_h.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(tree_clf_h.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(knn_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = [{'C':[.01, .1, .75, 1, 1.5, 2]}]\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3, \n",
    "                              scoring=make_scorer(roc_auc_score), verbose=5\n",
    "                             )\n",
    "lr_grid_search.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = lr_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(lr_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(lr_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.855103474706183\n",
      "ROC: 0.8718733215434405\n",
      "PPV: 0.8837131616064138\n",
      "NPV: 0.6787185354691075\n",
      "Sensitivity: 0.9443144409629953\n",
      "Specificity: 0.48630923102147894\n",
      "G-Mean: 0.6776642454986038\n",
      "Confusion matrix:\n",
      "[[ 2966  3133]\n",
      " [ 1404 23809]]\n"
     ]
    }
   ],
   "source": [
    "# class_weight={1:1, 0:2}\n",
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(X_train, Y_train.astype(int))\n",
    "#lr.fit(X_train, Y_train.astype(int))\n",
    "results(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('histo3v', 81.22515203470718)\n",
      "2 ('cslymphn', 19.747983364643506)\n",
      "3 ('csexten', 17.36882872274285)\n",
      "4 ('surgprif', 5.902625863164482)\n",
      "5 ('csmetsdx', 5.864142874717367)\n",
      "6 ('reg', 3.5583889647114817)\n",
      "7 ('age_dx', 1.983152159998009)\n",
      "8 ('primsite', 1.4472213224181907)\n",
      "9 ('no_surg', 1.106293304229804)\n",
      "10 ('summ2k', 0.9045600682571576)\n",
      "11 ('dx_conf', 0.822995423731435)\n",
      "12 ('csmteval', 0.7554901126371617)\n",
      "13 ('csrgeval', 0.6793666993749904)\n",
      "14 ('grade', 0.5661703113367789)\n",
      "15 ('mar_stat', 0.4106388661168552)\n",
      "16 ('cstseval', 0.3981151837811313)\n",
      "17 ('beho3v', 0.35956860352786124)\n",
      "18 ('eod10_pn', 0.2788893717979616)\n",
      "19 ('sex', 0.0907788678222121)\n",
      "20 ('maligcount', 0.07134211915646624)\n",
      "21 ('tumsiz', 0.06339024311122199)\n",
      "22 ('race', 0.006509939863246353)\n"
     ]
    }
   ],
   "source": [
    "feature_importance_rank(lr.coef_[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in enumerate(lr.coef_[0]):\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(enumerate(lr.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scoring=make_scorer(roc_auc_score)\n",
    "param_grid = [{'max_features':[175,200], 'n_estimators':[10,15,20], 'min_samples_leaf':[150,175,200]}]\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "            param_grid, cv=3, scoring=make_scorer(roc_auc_score), \n",
    "            verbose=5\n",
    ")\n",
    "rf_grid_search.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rf_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(rf_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 0.8534427695452222\n",
      "ROC: 0.8731099180579104\n",
      "PPV: 0.8873779113448534\n",
      "NPV: 0.6609121909633419\n",
      "Sensitivity: 0.9368976321738786\n",
      "Specificity: 0.5084440072142974\n",
      "G-Mean: 0.6901883702671856\n",
      "Confusion matrix:\n",
      "[[ 3101  2998]\n",
      " [ 1591 23622]]\n"
     ]
    }
   ],
   "source": [
    "# class_weight={1:1,0:3}\n",
    "rf_clf = RandomForestClassifier(n_estimators=20, min_samples_leaf=150, max_features=200, random_state=42)\n",
    "rf_clf.fit(X_train, Y_train)\n",
    "results(rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('csmetsdx', 0.3724755773627602)\n",
      "2 ('summ2k', 0.1870926635503274)\n",
      "3 ('no_surg', 0.10790548042915481)\n",
      "4 ('age_dx', 0.08759983570483185)\n",
      "5 ('surgprif', 0.06683252563393596)\n",
      "6 ('eod10_pn', 0.06653326035483957)\n",
      "7 ('tumsiz', 0.033703507303795135)\n",
      "8 ('grade', 0.016875652890442405)\n",
      "9 ('cslymphn', 0.012439229464724132)\n",
      "10 ('csexten', 0.009074781383398177)\n",
      "11 ('primsite', 0.008652183626317292)\n",
      "12 ('dx_conf', 0.007333646445526323)\n",
      "13 ('mar_stat', 0.006122074376357596)\n",
      "14 ('histo3v', 0.0059149450132651585)\n",
      "15 ('maligcount', 0.003814146359879019)\n",
      "16 ('sex', 0.0021769235803424)\n",
      "17 ('reg', 0.0018854777886249514)\n",
      "18 ('csmteval', 0.0014160279795975826)\n",
      "19 ('csrgeval', 0.0011862608359948848)\n",
      "20 ('cstseval', 0.0011392800356132648)\n",
      "21 ('beho3v', 0.001119489155326443)\n",
      "22 ('race', 0.00010659330564055625)\n"
     ]
    }
   ],
   "source": [
    "feature_importance_rank(rf_clf.feature_importances_, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(rf_clf.feature_importances_), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(rf_grid_search, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_clf = LinearSVC(C=.01)\n",
    "svm_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_rank(svm_clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(svm_clf.coef_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "clf1 = RandomForestClassifier(n_estimators=20, min_samples_leaf=300, max_features=225)\n",
    "clf2 = LogisticRegression(C=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=20, \n",
    "                           algorithm=\"SAMME.R\", learning_rate=1)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[\n",
    "    ('rf', clf1), ('lr', clf2), ('ab', clf4)\n",
    "], voting='soft')\n",
    "eclf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, max_samples=3000,\n",
    "                           bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(bag_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "bbc = BalancedBaggingClassifier(DecisionTreeClassifier(), n_estimators=200, max_samples=3000,\n",
    "                           bootstrap=True, n_jobs=-1)\n",
    "bbc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(bbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scoring=make_scorer(roc_auc_score)\n",
    "param_grid = [{\"n_estimators\":[100, 115, 130, 145], \"learning_rate\":[.6, .7, .8, .9, 1]}]\n",
    "ab_grid_search = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME.R\"), \n",
    "            param_grid, cv=3, scoring=make_scorer(roc_auc_score), \n",
    "            verbose=5\n",
    ")\n",
    "ab_grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = ab_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best: \" + str(ab_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(ab_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, \n",
    "                           algorithm=\"SAMME.R\", learning_rate=1)\n",
    "ab_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(ab_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('csexten', 0.195)\n",
      "2 ('age_dx', 0.12)\n",
      "3 ('histo3v', 0.10500000000000001)\n",
      "4 ('csmetsdx', 0.095)\n",
      "5 ('tumsiz', 0.075)\n",
      "6 ('eod10_pn', 0.075)\n",
      "7 ('surgprif', 0.065)\n",
      "8 ('primsite', 0.04)\n",
      "9 ('summ2k', 0.04)\n",
      "10 ('reg', 0.039999999999999994)\n",
      "11 ('grade', 0.025)\n",
      "12 ('no_surg', 0.025)\n",
      "13 ('mar_stat', 0.02)\n",
      "14 ('cslymphn', 0.02)\n",
      "15 ('csrgeval', 0.02)\n",
      "16 ('dx_conf', 0.015)\n",
      "17 ('cstseval', 0.01)\n",
      "18 ('maligcount', 0.005)\n",
      "19 ('sex', 0.005)\n",
      "20 ('beho3v', 0.005)\n",
      "21 ('csmteval', 0.005)\n",
      "22 ('race', 0.0)\n"
     ]
    }
   ],
   "source": [
    "feature_importance_rank(ab_clf.feature_importances_, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=400)\n",
    "gb_clf.fit(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(gb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(ratio={0: 27723, 1:27723},random_state=42)\n",
    "X_train_res, Y_train_res = sm.fit_sample(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "us = RandomUnderSampler(ratio={0:Counter(Y_train)[0], 1:Counter(Y_train)[0]})\n",
    "X_train_res, Y_train_res = us.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "os = RandomOverSampler(ratio={0:20000, 1:27731})\n",
    "X_train_res, Y_train_res = os.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, init='pca', random_state=97, verbose=5)\n",
    "size = 2000\n",
    "X_tsne = tsne.fit_transform(X[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_exp = Y2[:size]\n",
    "idx_not_survive = np.where(Y_exp==0)[0]\n",
    "idx_survive = np.where(Y_exp==1)[0]\n",
    "\n",
    "\n",
    "plt.xlim((-100,200))\n",
    "plt.ylim((-50,50))\n",
    "plt.scatter(X_tsne[idx_not_survive][:,0], X_tsne[idx_not_survive][:,1], color='red')\n",
    "plt.scatter(X_tsne[idx_survive][-200:,0], X_tsne[idx_survive][-200:,1], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter([1,2,3],[4,5,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3, init='pca', random_state=97, verbose=5)\n",
    "size = 5000\n",
    "X_tsne = tsne.fit_transform(X[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "Y_exp = Y2[:size]\n",
    "idx_not_survive = np.where(Y_exp==0)[0]\n",
    "idx_survive = np.where(Y_exp==1)[0]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(221, projection='3d')\n",
    "ax1.set_zlim(-3,3)\n",
    "ax1.set_ylim(-20,20)\n",
    "ax1.set_xlim(-100,100)\n",
    "\n",
    "ax2 = fig.add_subplot(222, projection='3d')\n",
    "ax2.set_zlim(-3,3)\n",
    "ax2.set_ylim(-20,20)\n",
    "ax2.set_xlim(-100,100)\n",
    "\n",
    "ax2.scatter(xs=X_tsne[idx_not_survive][:,0], ys=X_tsne[idx_not_survive][:,1], zs=X_tsne[idx_not_survive][:,2], color='red')\n",
    "\n",
    "ax1.scatter(xs=X_tsne[idx_survive][begin:,0], ys=X_tsne[idx_survive][begin:,1], zs=X_tsne[idx_survive][begin:,2],color='blue')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
